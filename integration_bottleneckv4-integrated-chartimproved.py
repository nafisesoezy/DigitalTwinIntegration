# Auto-generated by ChatGPT — two-group (Mismatch / Metadata Gap) rewrite
# Usage:
#   python model_schema_matcher.py /path/to/dir_or_files... [--debug]
# Scans YAMLs, groups by "<N>-<ROLE>-*.yaml", extracts metadata, infers AB pattern,
# evaluates bottlenecks, writes "match_report.csv", and saves figures in ./figs

import os
import re
import sys
import yaml
import traceback
import pandas as pd
from typing import List, Dict, Any, Tuple, Optional, Set, Iterable
from dataclasses import dataclass, field
from collections import defaultdict



# --- Optional plotting deps (safe fallback if missing) ---
HAS_MPL = True
try:
    import numpy as np
    import matplotlib
    matplotlib.use("Agg")  # set backend BEFORE importing pyplot
    import matplotlib.pyplot as plt

    # --- Global Matplotlib style (applies to all plots) ---
    plt.style.use("seaborn-v0_8-whitegrid")  # clean background
    plt.rcParams["axes.prop_cycle"] = plt.cycler(color=plt.cm.Set2.colors)  # categorical colors
    plt.rcParams["figure.dpi"] = 300
    plt.rcParams["savefig.dpi"] = 300
    plt.rcParams["font.size"] = 9
    plt.rcParams["axes.titlesize"] = 11
    plt.rcParams["axes.labelsize"] = 9
    plt.rcParams["legend.fontsize"] = 8

except Exception as _e:
    HAS_MPL = False
    print("Warning: matplotlib not available; skipping figure generation. Details:", _e)


def get_nested(dct, dotted_key):
    keys = dotted_key.split(".")
    for k in keys:
        if not isinstance(dct, dict) or k not in dct:
            return None
        dct = dct[k]
    return dct

# --- Optional plotting deps (safe fallback if missing) ---
HAS_MPL = True
try:
    import numpy as np
    import matplotlib
    matplotlib.use("Agg")  # write-to-file backend
    import matplotlib.pyplot as plt
except Exception as _e:
    HAS_MPL = False
    print("Warning: matplotlib not available; skipping figure generation. Details:", _e)

# ============================================================
# Text/Token utilities
# ============================================================

STOPWORDS = {
    "a","an","and","as","at","beneath","by","canonical","component","components","coupled",
    "data","dataset","datasets","description","exchange","exchanges","expected","field","fields",
    "flux","fluxes","for","from","ice","in","input","inputs","intended","into","measurement",
    "measurements","model","models","ocean","of","on","or","output","outputs","rate","rates",
    "schema","sea","shelf","surface","the","to","under","variable","variables","with"
}

def normalize_phrase(s: str) -> str:
    if not s:
        return ""
    s = s.replace("–", "-")
    s = re.sub(r"\s+and\s+", ", ", s, flags=re.IGNORECASE)
    s = s.replace("/", " / ")
    s = re.sub(r"[\(\)\[\]]", " ", s)  # drop bracket content (units) for "name" comparison
    s = re.sub(r"[:,;|]+", ",", s)
    s = re.sub(r"\s+", " ", s)
    return s.strip().lower()

def split_variables(text: str) -> List[str]:
    text = normalize_phrase(text)
    if not text:
        return []
    parts = [p.strip() for p in text.split(",") if p.strip()]
    out: List[str] = []
    for p in parts:
        p2 = re.sub(r"\s+", " ", p).strip()
        if p2:
            out.append(p2)
    return out

def tokenize(s: str) -> Set[str]:
    s = normalize_phrase(s)
    tokens = re.findall(r"[a-zA-Z0-9\-\+°²/]+", s)
    return {t for t in tokens if t not in STOPWORDS and len(t) > 1}

def phrase_similarity(a: str, b: str) -> float:
    if not a or not b:
        return 0.0
    if a == b:
        return 1.0
    if a in b or b in a:
        return 0.9
    ta, tb = tokenize(a), tokenize(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    union = len(ta | tb)
    return inter / union if union else 0.0

def list_best_pairwise(src: List[str], dst: List[str]) -> Tuple[float, List[Tuple[str, str, float]]]:
    """Average of best matches from src to dst + list of (src, best_dst, score)."""
    if not src or not dst:
        return (0.0, [])
    matches = []
    scs: List[float] = []
    for s in src:
        best_b, best = "", 0.0
        for d in dst:
            sim = phrase_similarity(s, d)
            if sim > best:
                best, best_b = sim, d
        matches.append((s, best_b, best))
        scs.append(best)
    return ((sum(scs)/len(scs)) if scs else 0.0, matches)

def jaccard_token_similarity(a: str, b: str) -> float:
    ta, tb = tokenize(a), tokenize(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    union = len(ta | tb)
    return inter / union if union else 0.0

def dedupe(items: Iterable[str]) -> List[str]:
    seen, out = set(), []
    for x in items:
        if x not in seen:
            out.append(x)
            seen.add(x)
    return out

# ============================================================
# Dataclasses
# ============================================================

@dataclass
class IOSchema:
    variables: List[str] = field(default_factory=list)
    units: List[str] = field(default_factory=list)

@dataclass
class ModelMeta:
    file: str
    group: str
    role: str
    name: str
    root: Dict[str, Any]
    outputs: IOSchema = field(default_factory=IOSchema)
    inputs: IOSchema = field(default_factory=IOSchema)
    ab_pattern: str = ""
    ab_in: List[str] = field(default_factory=list)
    ab_out: List[str] = field(default_factory=list)
    canonical_exchange: List[str] = field(default_factory=list)
    fields: Dict[str, Any] = field(default_factory=dict)  # bag of extracted fields

# ============================================================
# Filename grouping
# ============================================================

def guess_group_role_from_filename(path: str) -> Tuple[str, str]:
    base = os.path.basename(path)
    # only accept A, B, or AB-intended
    m = re.match(r"^(\d+)-(A|B|AB-Intended|AB-Integrated)(?:[-_.]|$)", base, flags=re.IGNORECASE)
    group = m.group(1) if m else "unknown"
    role = m.group(2).upper() if m else "unknown"
    print(f"[DEBUG] {base} -> group={group}, role={role}")

    return group, role

# ============================================================
# YAML loading
# ============================================================

def load_yaml_models(paths: List[str]) -> List[ModelMeta]:
    models: List[ModelMeta] = []
    for p in paths:
        try:
            with open(p, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
        except Exception as e:
            print(f"Warning: failed to parse {p}: {e}")
            continue
        if isinstance(data, dict) and data:
            name = list(data.keys())[0]
            root = data[name]
        else:
            name = os.path.splitext(os.path.basename(p))[0]
            root = data if isinstance(data, dict) else {}
        group, role = guess_group_role_from_filename(p)
        models.append(ModelMeta(file=p, group=group, role=role, name=name, root=root or {}))
    return models

# ============================================================
# Generic recursive field extraction
# ============================================================

def normkey(k: str) -> str:
    return re.sub(r"[^a-z0-9]+", "_", k.strip().lower())

FIELD_ALIASES: Dict[str, List[str]] = {
    # Enterprise
    "title": ["title","name"],
    "model_version": ["model_version","version","design_version"],
    "description": ["description","summary","abstract"],
    "keywords": ["keywords","tags"],
    "model_type": ["model_type","type"],
    "scope": ["scope"],
    "purpose_pattern": ["purpose_pattern","purpose_and_pattern","purpose","pattern"],
    "assumptions": ["assumptions"],
    "links_to_publications_and_reports": ["links","publications","reports","references","links_to_publications_and_reports"],
    "conceptual_model_evaluation": ["conceptual_model_evaluation","conceptual_evaluation"],
    "calibration_tools_data": ["calibration","calibration_tools","calibration_tools_data","calibration_data"],
    "validation_capabilities": ["validation_capabilities","validation"],
    "sensitivity_analysis": ["sensitivity_analysis","sensitivity"],
    "uncertainty_analysis": ["uncertainty_analysis","uncertainty"],
    "authors_unique_identifier": ["authors_unique_identifier","authors","contributors","author_ids","orcid"],
    "contributor_role": ["contributor_role","roles"],
    # Information
    "unique_identifier": ["unique_identifier","uuid","doi","id"],
    "parameters": ["parameters","params"],
    "datasets": ["datasets","data_sources"],
    "data": ["data","outputs","output_description"],
    "dimensionality": ["dimensionality","dims"],
    "spatial_extent_coverage": ["spatial_extent","spatial_coverage","extent","coverage"],
    "spatial_resolution": ["spatial_resolution","grid_resolution","grid_size"],
    "variable_spatial_resolution": ["variable_spatial_resolution","adaptive_spatial"],
    "temporal_extent_coverage": ["temporal_extent","temporal_coverage","time_period","time_extent"],
    "time_steps_temporal_resolution": ["time_steps","temporal_resolution","time_step","timestep"],
    "variable_temporal_resolution": ["variable_temporal_resolution","adaptive_temporal"],
    # Computational
    "error_handling": ["error_handling","errors","exceptions"],
    "integration_pattern": ["integration.pattern","integration_pattern","pattern"],  # AB explicit
    "communication_mechanism": ["communication","io_mechanism","interaction_style","binding","interface"],
    "execution_instructions": ["execution_instructions","run_instructions","how_to_run","runbook"],
    "acknowledgment_protocols": ["acknowledgment_protocols","ack_protocols","acknowledgement_protocols"],
    "execution_constraints": ["execution_constraints","ordering","timing_constraints"],
    # Engineering
    "parallel_execution": ["parallel_execution","concurrency","parallelism"],
    "latency_expectations": ["latency_expectations","latency","sla"],
    "data_synchronization": ["data_synchronization","sync_strategy","synchronization"],
    # Technology
    "programming_language": ["programming_language","language","lang"],
    "availability_of_source_code": ["availability_of_source_code","source_code","repo","repository"],
    "implementation_verification": ["implementation_verification","tests","verification"],
    "software_specification_and_requirements": ["software_specification_and_requirements","software_requirements","software_stack","dependencies"],
    "hardware_specification_and_requirements": ["hardware_specification_and_requirements","hardware_requirements","hardware","resources"],
    "license": ["license","licence"],
    "landing_page": ["landing_page","homepage","url"],
    "distribution_version": ["distribution_version","package_version","release_version"],
    "file_formats": ["file_formats","formats","file_format"],
    # IO (kept for legacy logic)
    "input": ["input"],
    "output": ["output"],
    "integrated_input": ["integrated_input"],
}

def dig_for_keypaths(d: Any, path: str) -> List[Any]:
    """Retrieve values by a dotted path (supports simple nesting)."""
    parts = path.split(".")
    cur = d
    for p in parts:
        if isinstance(cur, dict) and p in cur:
            cur = cur[p]
        else:
            return []
    return [cur]

def collect_values(root: Dict[str, Any], alias_list: List[str]) -> List[Any]:
    vals: List[Any] = []
    root = root or {}
    for ali in alias_list:
        if "." in ali:
            vals.extend(dig_for_keypaths(root, ali))
        elif ali in root:
            vals.append(root[ali])
        nk_target = normkey(ali)
        def rec(x: Any):
            if x is None:
                return
            if isinstance(x, dict):
                for k, v in x.items():
                    if normkey(k) == nk_target:
                        vals.append(v)
                    rec(v)
            elif isinstance(x, list):
                for it in x:
                    rec(it)
        rec(root)
    return vals

def extract_field(model: ModelMeta, key: str) -> List[str]:
    alis = FIELD_ALIASES.get(key, [key])
    vals = collect_values(model.root, alis)
    flat: List[str] = []
    for v in vals:
        if v is None:
            continue
        if key in ("input","output","integrated_input"):
            continue  # IO handled elsewhere
        if isinstance(v, dict):
            for vv in v.values():
                if isinstance(vv, (str,int,float)):
                    flat.append(str(vv))
        elif isinstance(v, list):
            for it in v:
                if it is None:
                    continue
                if isinstance(it, (str,int,float)):
                    flat.append(str(it))
                elif isinstance(it, dict):
                    for vv in it.values():
                        if isinstance(vv, (str,int,float)):
                            flat.append(str(vv))
        elif isinstance(v, (str,int,float)):
            flat.append(str(v))
    return dedupe([normalize_phrase(x) for x in flat if str(x).strip()])

# ============================================================
# IO extraction
# ============================================================

def coerce_var_list(v: Any) -> List[str]:
    if v is None:
        return []
    if isinstance(v, str):
        return split_variables(v)
    if isinstance(v, list):
        out: List[str] = []
        for item in v:
            if item is None:
                continue
            if isinstance(item, str):
                out.extend(split_variables(item))
            elif isinstance(item, dict):
                for k in ("name","variable","var","id","description","label"):
                    if isinstance(item.get(k), str):
                        out.extend(split_variables(item[k]))
        return dedupe(out)
    if isinstance(v, dict):
        out: List[str] = []
        for k in ("variables","names","list","description"):
            if k in v and isinstance(v[k], (str,list)):
                out.extend(coerce_var_list(v[k]))
        return dedupe(out)
    return []

def coerce_units_list(v: Any) -> List[str]:
    if v is None:
        return []
    if isinstance(v, str):
        return [u.strip() for u in re.split(r"[;,]", v) if u.strip()]
    if isinstance(v, list):
        return [str(u).strip() for u in v if (u is not None and str(u).strip())]
    if isinstance(v, dict):
        out = []
        for k in ("units","unit"):
            if k in v:
                out.extend(coerce_units_list(v[k]))
        return out
    return []

def parse_ab_pattern(r: Dict[str, Any]) -> str:
    # 1. Always check explicit field first
    integ = r.get("integration")
    if isinstance(integ, dict):
        pat = integ.get("pattern")
        if isinstance(pat, str) and pat.strip():
            # Normalize common variants
            txt = pat.lower()
            if "embedded" in txt:
                return "Embedded"
            if "integrated" in txt or "tight" in txt:
                return "Integrated"
            if "shared" in txt:
                return "Shared"
            if "loose" in txt:
                return "Loose"
            if "one-way" in txt or "one way" in txt:
                return "One-Way"
            return pat.strip()   # fallback: return whatever string was written

    # 2. Only if no explicit field, fall back to scanning keywords
    ...



def extract_io(model: ModelMeta, debug: bool = False) -> None:
    r = model.root if isinstance(model.root, dict) else {}
    # Outputs
    out_vars, out_units = [], []
    if isinstance(r.get("output"), dict):
        oo = r["output"]
        out_vars = coerce_var_list(oo.get("variables"))
        out_units = coerce_units_list(oo.get("units"))
    if not out_vars and isinstance(r.get("data"), dict):
        d = r["data"]
        out_vars = coerce_var_list(d.get("variables"))
        out_units = coerce_units_list(d.get("units"))

    # Inputs
    in_vars, in_units = [], []
    if isinstance(r.get("input"), dict):
        ii = r["input"]
        in_vars.extend(coerce_var_list(ii.get("variables")))
        in_units.extend(coerce_units_list(ii.get("units")))
        if isinstance(ii.get("description"), str):
            in_vars.extend(split_variables(ii["description"]))

    if isinstance(r.get("integrated_input"), list):
        for item in r["integrated_input"]:
            if isinstance(item, dict):
                in_vars.extend(split_variables(item.get("description", "")))

    if isinstance(r.get("datasets"), list):
        for ds in r["datasets"]:
            if isinstance(ds, dict) and isinstance(ds.get("dependencies"), list):
                for dep in ds["dependencies"]:
                    if isinstance(dep, str):
                        in_vars.extend(split_variables(dep))

    model.outputs = IOSchema(variables=dedupe(out_vars), units=dedupe(out_units))
    model.inputs  = IOSchema(variables=dedupe(in_vars), units=dedupe(in_units))

    # AB extras
    if model.role in {"AB-INTENDED", "AB-INTEGRATED"}:
        model.ab_pattern = parse_ab_pattern(r)
        if isinstance(r.get("input"), dict):
            model.ab_in = dedupe(coerce_var_list(r["input"].get("variables")))
        if isinstance(r.get("output"), dict):
            model.ab_out = dedupe(coerce_var_list(r["output"].get("variables")))
        canon: List[str] = []
        if isinstance(r.get("integrated_input"), list):
            for item in r["integrated_input"]:
                if isinstance(item, dict):
                    canon.extend(split_variables(item.get("description", "")))
        canon.extend(model.ab_in)
        canon.extend(model.ab_out)
        if not canon:
            for k in ("description", "purpose_pattern", "integration"):
                val = r.get(k, "")
                if isinstance(val, dict):
                    for vv in val.values():
                        if isinstance(vv, str):
                            canon.extend(split_variables(vv))
                elif isinstance(val, str):
                    canon.extend(split_variables(val))
        model.canonical_exchange = dedupe(canon)

    # Populate generic fields bag
    for k in FIELD_ALIASES.keys():
        if k in ("input","output","integrated_input"):
            continue
        model.fields[k] = extract_field(model, k)

    if debug:
        print(f"\n[DEBUG] {model.file} ({model.role})")
        print(f"  outputs: {model.outputs.variables or '(none)'}")
        print(f"  inputs:  {model.inputs.variables or '(none)'}")
        if model.role in {"AB-INTENDED", "AB-INTEGRATED"}:
            print(f"  AB in:   {model.ab_in or '(none)'}")
            print(f"  AB out:  {model.ab_out or '(none)'}")
            print(f"  AB pat:  {model.ab_pattern or '(unspecified)'}")
            print(f"  AB canon:{model.canonical_exchange or '(none)'}")

# ============================================================
# Pattern inference (no Tool-Coupling)
# ============================================================

INMEMORY_KEYS = ["in-memory", "in memory", "shared memory"]
TOOL_KEYS = ["fabm", "esmf", "oasis", "oasis-mct", "mct", "framework", "mediator", "coupler"]
SYNC_KEYS = ["every physics step", "every step", "synchronous", "same timestep", "same time step"]
FILE_KEYS = ["netcdf", "csv", "file", "files", "post-run", "offline", "batch"]
REPO_KEYS = ["shared repository", "common data store", "database", "object store"]

def text_from_fields(*vals: Any) -> str:
    parts: List[str] = []
    for v in vals:
        if v is None:
            continue
        if isinstance(v, str):
            parts.append(v)
        elif isinstance(v, list):
            for it in v:
                if it is None:
                    continue
                if isinstance(it, dict):
                    parts.extend([str(x) for x in it.values() if isinstance(x, str)])
                elif isinstance(it, str):
                    parts.append(it)
        elif isinstance(v, dict):
            for x in v.values():
                if isinstance(x, str):
                    parts.append(x)
    return normalize_phrase(" ".join(parts))

def contains_any(text: str, keys: List[str]) -> bool:
    t = text.lower()
    return any(k in t for k in keys)

def detect_integration_pattern(a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta]) -> Tuple[str, str]:
    if ab and ab.ab_pattern:
        # Map 'Tool/Framework/Coupler' declarations to Shared (no Tool-Coupling label)
        if ab.ab_pattern.lower() not in {"one-way","loose","shared","integrated","embedded"}:
            return "Shared", f"AB declared '{ab.ab_pattern}' → mapped to 'Shared'."
        return ab.ab_pattern, f"AB declares pattern '{ab.ab_pattern}'."
    a_text = text_from_fields(a.root)
    b_text = text_from_fields(b.root)
    ab_text = text_from_fields(ab.root if ab else {})
    union_text = " ".join([a_text, b_text, ab_text])

    has_inmem = contains_any(union_text, INMEMORY_KEYS)
    has_tool  = contains_any(union_text, TOOL_KEYS)
    has_sync  = contains_any(union_text, SYNC_KEYS)
    has_file  = contains_any(union_text, FILE_KEYS)
    has_repo  = contains_any(union_text, REPO_KEYS)

    if has_inmem:
        return "Embedded", "Detected in-memory / shared memory phrasing."
    if has_sync and (has_repo or has_tool):
        return "Shared", "Detected synchronous cadence with shared store/coupler."
    if has_file or has_repo or has_tool:
        return "Loose", "Detected file/repo/coupler exchange without in-memory."
    return "One-Way", "Defaulted to One-Way."

# ============================================================
# Enterprise semantic coverage vs AB
# ============================================================

SEM_COV_MIN = 0.5  # threshold for union coverage to call "Match"
MIN_VAR_SIM = 0.5  # for IO semantic overlap

#def tokens_from_value(s: str) -> Set[str]:
#   return tokenize(s) if s else set()
EXTRA_ENTERPRISE_STOP = {
    "project","phase","framework","user","defined","coupled","tbd"
}

def enterprise_tokens(s: str) -> Set[str]:
    """Tokenization tuned for Enterprise 'Semantic Mismatch' fields (Title, Description, etc.)."""
    if not s:
        return set()
    s = normalize_phrase(s)
    # Split common joiners so 'mismip+-isomip+' -> 'mismip+' 'isomip+'
    s = re.sub(r"[_/:]+", " ", s)
    s = s.replace("-", " ")

    # Normalize 'plus' <-> '+'
    s = re.sub(r"\bplus\b", "+", s)

    # Base tokens (allow '+', drop other punctuation)
    base = re.findall(r"[a-zA-Z0-9\+]+", s)
    toks = {t for t in base if t not in STOPWORDS and t not in EXTRA_ENTERPRISE_STOP and len(t) > 1}

    # Expand variants: 'mismip+' => {'mismip+', 'mismipplus', 'mismip'}
    def expand_plus(t: str) -> Set[str]:
        out = {t}
        if t.endswith("+"):
            stem = t[:-1]
            if stem:
                out |= {stem, stem + "plus"}
        if t.endswith("plus"):
            stem = t[:-4]
            if stem:
                out |= {stem, stem + "+"}
        return out

    expanded: Set[str] = set()
    for t in toks:
        expanded |= expand_plus(t)

    # Domain-specific aliasing (easy to add more later)
    aliases = {
        "mismip": {"mismip", "mismip+", "mismipplus"},
        "isomip": {"isomip", "isomip+", "isomipplus"},
    }
    final = set(expanded)
    for t in list(expanded):
        for family in aliases.values():
            if t in family:
                final |= family

    return final

def tokens_from_value(s: str) -> Set[str]:
    # IMPORTANT: this tokens_from_value is only called by the Enterprise "Semantic Mismatch" code.
    # (Other checks use phrase_similarity() which still uses the generic tokenize().)
    return enterprise_tokens(s)


def join_field_values(model: Optional[ModelMeta], key: str) -> str:
    if not model:
        return ""
    return "; ".join(model.fields.get(key, []))

def coverage_vs_ab(src_text: str, ab_text: str) -> Tuple[float, List[str], List[str]]:
    ab_tok = tokens_from_value(ab_text)
    if not ab_tok:
        return 0.0, [], []
    src_tok = tokens_from_value(src_text)
    covered = sorted(list(ab_tok & src_tok))
    uncovered = sorted(list(ab_tok - src_tok))
    cov = (len(covered) / len(ab_tok)) if ab_tok else 0.0
    return cov, covered, uncovered

def union_coverage_vs_ab(a_text: str, b_text: str, ab_text: str) -> Tuple[float, List[str], List[str]]:
    ab_tok = tokens_from_value(ab_text)
    if not ab_tok:
        return 0.0, [], []
    a_tok = tokens_from_value(a_text)
    b_tok = tokens_from_value(b_text)
    union_tok = a_tok | b_tok
    covered = sorted(list(ab_tok & union_tok))
    uncovered = sorted(list(ab_tok - union_tok))
    cov = (len(covered) / len(ab_tok)) if ab_tok else 0.0
    return cov, covered, uncovered

def any_semantic_overlap(src_vars: List[str], dst_vars: List[str], min_sim: float = MIN_VAR_SIM) -> Tuple[bool, List[Tuple[str,str,float]]]:
    score, pairs = list_best_pairwise(src_vars, dst_vars)
    good = [(s,d,sc) for (s,d,sc) in pairs if sc >= min_sim]
    return (len(good) > 0, good)

def pretty_pairs(pairs: List[Tuple[str,str,float]]) -> str:
    if not pairs:
        return ""
    return "; ".join([f"{s} ↔ {d} ({sc:.2f})" for (s,d,sc) in pairs])

# ============================================================
# Helpers for row building and grouping
# ============================================================

def row(group: str, bottleneck: str, field: str, pattern: str, required_check: str,
        av: str, bv: str, abv: str, detail: str, result: str) -> Dict[str,Any]:
    """
    result ∈ {"Match","Mismatch","Missing"}.
    We'll derive two outcome groups:
      - 'Mismatch' (values present but don't align) if result=="Mismatch"
      - 'Metadata Gap' if result=="Missing"
    """
    return {
        "group": group,
        "bottleneck": bottleneck,
        "field": field,
        "pattern": pattern or "(unspecified)",
        "required_check": required_check,
        "A_value": av or "",
        "B_value": bv or "",
        "AB_value": abv or "",
        "detail": detail or "",
        "result": result
    }

def missing_of(names_to_values: List[Tuple[str, List[str]]]) -> List[str]:
    """Return list of actor labels (e.g., 'A.output') that are empty."""
    missing = []
    for label, values in names_to_values:
        if not values:
            missing.append(label)
    return missing

# ============================================================
# Viewpoint helpers (for charts)
# ============================================================

def bottleneck_viewpoint(name: str) -> str:
    n = name.lower()
    if n in ("semantic mismatch", "conceptual quality gap"):
        return "Domain"
    if n in ("data schema mismatch","temporal resolution mismatch","temporal coverage mismatch",
             "spatial resolution mismatch","spatial coverage mismatch","dimensionality mismatch"):
        return "Information"
    if n in ("communication mechanism mismatch","error handling mismatch","execution instruction gap","data synchronization"):
        return "Computational" if n != "data synchronization" else "Engineering"
    if n in ("parallel execution incompatibility","execution constraint mismatch",
             "acknowledgment protocol mismatch","latency expectation mismatch","data synchronization"):
        return "Engineering"
    return "Technology"


# ==== helpers used by the gradient rules (put above the 3 functions if needed) ====

def _pattern_level(p: str) -> int:
    order = {"One-Way": 1, "Loose": 2, "Shared": 3, "Integrated": 4, "Embedded": 5}
    return order.get(p or "", 3)

_TIGHT_TOKENS = ["in-memory", "in memory", "shared memory", "direct call", "api", "ffi"]
_SYNC_TOKENS  = ["synchronous", "lockstep", "barrier", "every step", "same timestep", "same time step"]
_LOWLAT_TOKENS = ["low latency", "substep", "sub-stepping", "real-time", "tight coupling"]

def _has_any(text: str, tokens: list[str]) -> bool:
    if not text:
        return False
    t = text.lower()
    return any(tok in t for tok in tokens)

def _join_nonempty(*xs: str) -> str:
    return " | ".join([x for x in xs if x])

def _presence(a: str, b: str, ab: str) -> tuple[bool, bool, bool]:
    return bool(a), bool(b), bool(ab)



# ============================================================
# Bottleneck checkers
# ============================================================

def check_semantic_mismatch(group: str, a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta], pattern: str) -> List[Dict[str,Any]]:
    fields = [
        ("Title", "title"),
        ("Model Version", "model_version"),
        ("Description", "description"),
        ("Keywords", "keywords"),
        ("Model Type", "model_type"),
        ("Scope", "scope"),
        ("Purpose & Pattern", "purpose_pattern"),
        ("Assumptions", "assumptions"),
    ]
    rows: List[Dict[str, Any]] = []

    for label, key in fields:
        A_val = join_field_values(a, key)
        B_val = join_field_values(b, key)
        AB_val = join_field_values(ab, key)

        # If AB is missing for the field entirely -> cannot judge alignment: this is a metadata gap.
        if not AB_val:
            rows.append(row(group, "Semantic Mismatch", label, pattern, "Coverage vs AB",
                            A_val, B_val, AB_val, "AB value missing.", "Missing"))
            continue

        if key == "model_version":
            # version requires exact equality to AB; if A or B missing version, it's a gap
            if not A_val and not B_val:
                rows.append(row(group, "Semantic Mismatch", label, pattern, "Exact equality to AB",
                                A_val, B_val, AB_val, "A & B versions missing.", "Missing"))
                continue
            a_ok = (A_val == AB_val) if A_val else False
            b_ok = (B_val == AB_val) if B_val else False
            if not A_val or not B_val:
                detail = f"A==AB:{'✓' if a_ok else '×'}; B==AB:{'✓' if b_ok else '×'}; note: one side missing"
                rows.append(row(group, "Semantic Mismatch", label, pattern, "A or B must equal AB exactly",
                                A_val, B_val, AB_val, detail, "Missing"))
            else:
                u_ok = a_ok or b_ok
                detail = f"A==AB:{'✓' if a_ok else '×'}; B==AB:{'✓' if b_ok else '×'}"
                res = "Match" if u_ok else "Mismatch"
                rows.append(row(group, "Semantic Mismatch", label, pattern, "A or B must equal AB exactly",
                                A_val, B_val, AB_val, detail, res))
            continue

        # Token coverage against AB; if either A or B is entirely missing for this field, it's a gap
        if not A_val and not B_val:
            rows.append(row(group, "Semantic Mismatch", label, pattern, "Coverage vs AB",
                            A_val, B_val, AB_val, "A & B values missing.", "Missing"))
            continue

        covA, coveredA, _ = coverage_vs_ab(A_val, AB_val) if A_val else (0.0, [], [])
        covB, coveredB, _ = coverage_vs_ab(B_val, AB_val) if B_val else (0.0, [], [])
        covU, coveredU, unU = union_coverage_vs_ab(A_val, B_val, AB_val)

        detail = (f"A→AB:{covA:.2f} (covered: {', '.join(coveredA) or '—'}) | "
                  f"B→AB:{covB:.2f} (covered: {', '.join(coveredB) or '—'}) | "
                  f"A∪B→AB:{covU:.2f} (covered: {', '.join(coveredU) or '—'}) | "
                  f"uncovered_AB: {', '.join(unU) or '—'}")
        res = "Match" if covU >= SEM_COV_MIN else "Mismatch"
        rows.append(row(group, "Semantic Mismatch", label, pattern,
                        f"Coverage threshold ≥ {SEM_COV_MIN:.2f}",
                        A_val, B_val, AB_val, detail, res))
    return rows

def check_conceptual_quality_gap(group: str, a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta], pattern: str) -> List[Dict[str,Any]]:
    keys = [
        ("Links to Publications & Reports","links_to_publications_and_reports"),
        ("Authors’ Unique Identifier","authors_unique_identifier"),
        ("Conceptual Model Evaluation","conceptual_model_evaluation"),
        ("Calibration Tools/Data","calibration_tools_data"),
        ("Validation Capabilities","validation_capabilities"),
        ("Sensitivity Analysis","sensitivity_analysis"),
        ("Uncertainty Analysis","uncertainty_analysis"),
    ]
    rows=[]
    for label,key in keys:
        av = "; ".join(a.fields.get(key, []))
        bv = "; ".join(b.fields.get(key, []))
        # presence checks → gaps when any required side missing
        if av and bv:
            res, det = "Match","Both provide metadata."
        elif not av and not bv:
            res, det = "Missing","Neither provides metadata."
        else:
            res, det = "Missing","Only one provides metadata."
        rows.append(row(group,"Conceptual Quality Gap",label,pattern,"Pattern-agnostic",av,bv,"",det,res))
    return rows

# ---------- Information ----------

def check_information_viewpoint(group: str, a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta], pattern: str) -> List[Dict[str,Any]]:
    rows: List[Dict[str,Any]] = []
    # Data Schema Mismatch — semantic overlap rules per pattern
    Aout, Bin = a.outputs.variables, b.inputs.variables
    Bout, Ain = b.outputs.variables, a.inputs.variables
    ABin, ABout = (ab.ab_in if ab else []), (ab.ab_out if ab else [])

    patt = pattern or ""
    def val_str(v: List[str]) -> str:
        return "; ".join(v) if v else "(none)"

    # Requirement helper to decide result including Missing vs Mismatch
    def decide_result(ok: bool, actors: List[Tuple[str, List[str]]], detail: str) -> Tuple[str,str]:
        miss = missing_of(actors)
        if ok:
            return "Match", detail
        if miss:
            det = detail + (f" | missing: {', '.join(miss)}" if detail else f"missing: {', '.join(miss)}")
            return "Missing", det
        return "Mismatch", detail

    # Compute overlaps
    a2b_ok, a2b_pairs = any_semantic_overlap(Aout, Bin)
    b2a_ok, b2a_pairs = any_semantic_overlap(Bout, Ain)
    Ain_ABin_sim, _ = list_best_pairwise(a.inputs.variables, ABin) if ABin else (0.0, [])
    Bin_ABin_sim, _ = list_best_pairwise(b.inputs.variables, ABin) if ABin else (0.0, [])
    Aout_ABout_sim, _ = list_best_pairwise(a.outputs.variables, ABout) if ABout else (0.0, [])
    Bout_ABout_sim, _ = list_best_pairwise(b.outputs.variables, ABout) if ABout else (0.0, [])

    if patt == "One-Way":
        # A.out ↔ B.in
        res, det = decide_result(a2b_ok, [("A.output", Aout), ("B.input", Bin)],
                                 pretty_pairs(a2b_pairs))
        rows.append(row(group,"Data Schema Mismatch","A.output",pattern,"A.output ↔ B.input (≥1 semantic match)",
                        val_str(Aout), val_str(Bin), "", det, res))
        # A.in ↔ AB.in
        ok = Ain_ABin_sim > 0
        res, det = decide_result(ok, [("A.input", a.inputs.variables), ("AB.input", ABin)],
                                 f"sim={Ain_ABin_sim:.2f}")
        rows.append(row(group,"Data Schema Mismatch","A.input vs AB.input",pattern,"A.input ↔ AB.input (similarity>0)",
                        val_str(a.inputs.variables), "", val_str(ABin) or "(not specified)", det, res))
        # B.out ↔ AB.out
        ok = Bout_ABout_sim > 0
        res, det = decide_result(ok, [("B.output", b.outputs.variables), ("AB.output", ABout)],
                                 f"sim={Bout_ABout_sim:.2f}")
        rows.append(row(group,"Data Schema Mismatch","B.output vs AB.output",pattern,"B.output ↔ AB.output (similarity>0)",
                        "", val_str(b.outputs.variables), val_str(ABout) or "(not specified)", det, res))

    elif patt in ("Loose","Shared"):
        # A.out ↔ B.in
        res, det = decide_result(a2b_ok, [("A.output", Aout), ("B.input", Bin)],
                                 pretty_pairs(a2b_pairs))
        rows.append(row(group,"Data Schema Mismatch","A.output",pattern,"A.output ↔ B.input (≥1)",
                        val_str(Aout), val_str(Bin), "", det, res))
        # B.out ↔ A.in
        res, det = decide_result(b2a_ok, [("B.output", Bout), ("A.input", Ain)],
                                 pretty_pairs(b2a_pairs))
        rows.append(row(group,"Data Schema Mismatch","B.output",pattern,"B.output ↔ A.input (≥1)",
                        val_str(Bout), val_str(Ain), "", det, res))
        # (A or B).in ↔ AB.in
        ok = max(Ain_ABin_sim,Bin_ABin_sim) > 0
        res, det = decide_result(ok, [("A.input", a.inputs.variables), ("B.input", b.inputs.variables), ("AB.input", ABin)],
                                 f"max={max(Ain_ABin_sim,Bin_ABin_sim):.2f}")
        rows.append(row(group,"Data Schema Mismatch","(A or B).input vs AB.input",pattern,"(A or B).input ↔ AB.input (similarity>0)",
                        f"A.in:{val_str(a.inputs.variables)} | B.in:{val_str(b.inputs.variables)}","", val_str(ABin) or "(not specified)", det, res))
        # (A or B).out ↔ AB.out
        ok = max(Aout_ABout_sim,Bout_ABout_sim) > 0
        res, det = decide_result(ok, [("A.output", Aout), ("B.output", Bout), ("AB.output", ABout)],
                                 f"max={max(Aout_ABout_sim,Bout_ABout_sim):.2f}")
        rows.append(row(group,"Data Schema Mismatch","(A or B).output vs AB.output",pattern,"(A or B).output ↔ AB.output (similarity>0)",
                        f"A.out:{val_str(Aout)} | B.out:{val_str(Bout)}","", val_str(ABout) or "(not specified)", det, res))
    else:
        # Integrated/Embedded/Unspecified: any direction + AB alignments
        dir_ok = a2b_ok or b2a_ok
        res, det = decide_result(dir_ok, [("A.output", Aout), ("B.input", Bin), ("B.output", Bout), ("A.input", Ain)],
                                 f"A2B:{'✓' if a2b_ok else '×'}; B2A:{'✓' if b2a_ok else '×'}")
        rows.append(row(group,"Data Schema Mismatch","Direction (any)",pattern,"A.output ↔ B.input OR B.output ↔ A.input (≥1)",
                        f"A.out:{val_str(Aout)}", f"B.out:{val_str(Bout)}", "", det, res))
        ok = max(Ain_ABin_sim,Bin_ABin_sim) > 0
        res, det = decide_result(ok, [("A.input", a.inputs.variables), ("B.input", b.inputs.variables), ("AB.input", ABin)],
                                 f"max={max(Ain_ABin_sim,Bin_ABin_sim):.2f}")
        rows.append(row(group,"Data Schema Mismatch","(A or B).input vs AB.input",pattern,"(A or B).input ↔ AB.input (similarity>0)",
                        f"A.in:{val_str(a.inputs.variables)} | B.in:{val_str(b.inputs.variables)}","", val_str(ABin) or "(not specified)", det, res))
        ok = max(Aout_ABout_sim,Bout_ABout_sim) > 0
        res, det = decide_result(ok, [("A.output", Aout), ("B.output", Bout), ("AB.output", ABout)],
                                 f"max={max(Aout_ABout_sim,Bout_ABout_sim):.2f}")
        rows.append(row(group,"Data Schema Mismatch","(A or B).output vs AB.output",pattern,"(A or B).output ↔ AB.output (similarity>0)",
                        f"A.out:{val_str(Aout)} | B.out:{val_str(Bout)}","", val_str(ABout) or "(not specified)", det, res))

    # Other Information bottlenecks: if either side missing ⇒ Gap; else compare tokens
    info_simple = [
        ("Temporal Resolution Mismatch","time_steps_temporal_resolution"),
        ("Temporal Coverage Mismatch","temporal_extent_coverage"),
        ("Spatial Resolution Mismatch","spatial_resolution"),
        ("Spatial Coverage Mismatch","spatial_extent_coverage"),
        ("Dimensionality Mismatch","dimensionality"),
    ]
    for label, key in info_simple:
        av = "; ".join(a.fields.get(key, []))
        bv = "; ".join(b.fields.get(key, []))
        abv = "; ".join((ab.fields.get(key, []) if ab else []))
        if not av or not bv:
            res, det = "Missing", "One or both sides missing metadata."
        else:
            sim = jaccard_token_similarity(av, bv)
            res = "Match" if sim > 0 else "Mismatch"
            det = f"A↔B token-sim={sim:.2f} (>0 ⇒ aligned)"
        rows.append(row(group, label, key, pattern, "Common exchanged variables align semantically", av, bv, abv, det, res))
    return rows

# ---------- Computational ----------
# ===================== COMPUTATIONAL (hardness increases by pattern) =====================

def check_computational(group: str, a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta], pattern: str) -> List[Dict[str,Any]]:
    rows: List[Dict[str,Any]] = []
    lvl = _pattern_level(pattern)

    # -------- Communication Mechanism --------
    key = "communication_mechanism"
    av = "; ".join(a.fields.get(key, []))
    bv = "; ".join(b.fields.get(key, []))
    abv = "; ".join((ab.fields.get(key, []) if ab else []))
    a_has, b_has, ab_has = _presence(av, bv, abv)

    # Requirements escalate:
    # L1 (One-Way): not required; if nothing → Match (N/A). If present, any mechanism is OK.
    # L2 (Loose): require (A AND B) OR AB.
    # L3 (Shared): require (A AND B). AB optional.
    # L4 (Integrated): require (A AND B) AND any tight token in (A|B|AB).
    # L5 (Embedded): require (A AND B AND AB) AND tight token AND sync token.
    tight_present = _has_any(_join_nonempty(av, bv, abv), _TIGHT_TOKENS)
    sync_present  = _has_any(_join_nonempty(av, bv, abv), _SYNC_TOKENS)

    if   lvl == 1:
        res, det = "Match", "Not required for One-Way; any declared IO is acceptable."
    elif lvl == 2:
        ok = (a_has and b_has) or ab_has
        res, det = ("Match" if ok else "Missing",
                    "Both sides or AB canonical interface required.")
    elif lvl == 3:
        ok = (a_has and b_has)
        res = "Match" if ok else "Missing"
        det = "Both sides must declare mechanism." if not ok else "Both sides declare mechanism."
    elif lvl == 4:
        if not (a_has and b_has):
            res, det = "Missing", "Integrated requires both sides to declare mechanism."
        else:
            res, det = ("Match" if tight_present else "Mismatch",
                        "Expect tight/API/in-memory binding for Integrated.")
    else:  # lvl == 5
        required = a_has and b_has and ab_has
        if not required:
            res, det = "Missing", "Embedded requires A, B, and AB to declare mechanism."
        else:
            strict_ok = tight_present and sync_present
            res, det = ("Match" if strict_ok else "Mismatch",
                        "Embedded requires in-memory/API and synchronous cues.")
    rows.append(row(group,"Communication Mechanism Mismatch",key,pattern,
                    "Pattern-graded requirement",av,bv,abv,det,res))

    # -------- Error Handling --------
    key = "error_handling"
    av = "; ".join(a.fields.get(key, []))
    bv = "; ".join(b.fields.get(key, []))
    abv = "; ".join((ab.fields.get(key, []) if ab else []))
    a_has, b_has, ab_has = _presence(av, bv, abv)

    # L1: at least one side (or AB) → else Missing
    # L2: both sides OR AB
    # L3: both sides (AB optional)
    # L4: both sides AND if AB provided, each must be token-similar to AB
    # L5: both sides AND AB provided AND both similar to AB
    if   lvl == 1:
        ok = a_has or b_has or ab_has
        res, det = ("Match" if ok else "Missing",
                    "At least one of A/B/AB must define error handling.")
    elif lvl == 2:
        ok = (a_has and b_has) or ab_has
        res, det = ("Match" if ok else "Missing",
                    "Both A and B or AB canonical required.")
    elif lvl == 3:
        ok = a_has and b_has
        res, det = ("Match" if ok else "Missing",
                    "Shared requires A and B to define error handling.")
    elif lvl == 4:
        if not (a_has and b_has):
            res, det = "Missing", "Integrated requires A and B to define error handling."
        else:
            if ab_has:
                simA = jaccard_token_similarity(av, abv)
                simB = jaccard_token_similarity(bv, abv)
                ok = (simA > 0.0 and simB > 0.0)
                res = "Match" if ok else "Mismatch"
                det = f"A↔AB={simA:.2f}, B↔AB={simB:.2f} (>0 required if AB exists)"
            else:
                res, det = "Match", "A and B present; AB not provided."
    else:  # lvl == 5
        if not (a_has and b_has and ab_has):
            res, det = "Missing", "Embedded requires A, B, and AB error handling."
        else:
            simA = jaccard_token_similarity(av, abv)
            simB = jaccard_token_similarity(bv, abv)
            ok = (simA > 0.0 and simB > 0.0)
            res = "Match" if ok else "Mismatch"
            det = f"A↔AB={simA:.2f}, B↔AB={simB:.2f} (>0 required)."
    rows.append(row(group,"Error Handling Mismatch","error_handling",pattern,
                    "Pattern-graded requirement",av,bv,abv,det,res))

    # -------- Execution Instructions --------
    key = "execution_instructions"
    av = "; ".join(a.fields.get(key, []))
    bv = "; ".join(b.fields.get(key, []))
    a_has, b_has, _ = _presence(av, bv, "")

    # L1: require A only
    # L2: require A or B (or both)
    # L3: require both A and B
    # L4: require both A and B (AB optional)
    # L5: require both A and B (AB optional) – still presence-based
    if   lvl == 1:
        res, det = ("Match" if a_has else "Missing", "Producer (A) must provide run instructions.")
        rows.append(row(group,"Execution Instruction Gap","execution_instructions",pattern,
                        "Require A only", av,"","", det, res))
        rows.append(row(group,"Execution Instruction Gap","execution_instructions",pattern,
                        "B optional in One-Way", "",bv,"", "B optional", "Match"))
    elif lvl == 2:
        ok = a_has or b_has
        rows.append(row(group,"Execution Instruction Gap","execution_instructions",pattern,
                        "Require A or B", av,bv,"", "At least one side must provide.", "Match" if ok else "Missing"))
    else:
        ok = a_has and b_has
        rows.append(row(group,"Execution Instruction Gap","execution_instructions",pattern,
                        "Require both sides", av,bv,"", "Both A and B must provide.", "Match" if ok else "Missing"))

    return rows

# ======================= ENGINEERING (hardness increases by pattern) =======================

def check_engineering(group: str, a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta], pattern: str) -> List[Dict[str,Any]]:
    rows: List[Dict[str,Any]] = []
    lvl = _pattern_level(pattern)

    def eval_presence(label: str, key: str, needs_sync_tokens: bool = False, needs_lowlat: bool = False):
        av = "; ".join(a.fields.get(key, []))
        bv = "; ".join(b.fields.get(key, []))
        abv = "; ".join((ab.fields.get(key, []) if ab else []))
        a_has, b_has, ab_has = _presence(av, bv, abv)

        # Pattern-graded requiredness:
        # L1 One-Way: not required → always Match (N/A)
        # L2 Loose: require A or B (or AB if it makes sense)
        # L3 Shared: require A and B
        # L4 Integrated: require A and B; if needs_sync_tokens/lowlat set, require corresponding cues in (A|B|AB)
        # L5 Embedded: require A, B, and AB; and require those cues
        if lvl == 1:
            res, det = "Match", "Not required for One-Way."
        elif lvl == 2:
            ok = a_has or b_has or ab_has
            res, det = ("Match" if ok else "Missing",
                        "Loose requires at least one side (or AB) to declare this.")
        elif lvl == 3:
            ok = a_has and b_has
            res, det = ("Match" if ok else "Missing",
                        "Shared requires both A and B to declare this.")
        elif lvl == 4:
            if not (a_has and b_has):
                res, det = "Missing", "Integrated requires A and B to declare this."
            else:
                if needs_sync_tokens or needs_lowlat:
                    text = _join_nonempty(av, bv, abv)
                    ok_sync = True
                    if needs_sync_tokens:
                        ok_sync = _has_any(text, _SYNC_TOKENS)
                    ok_lat = True
                    if needs_lowlat:
                        ok_lat = _has_any(text, _LOWLAT_TOKENS)
                    ok = ok_sync and ok_lat
                    res, det = ("Match" if ok else "Mismatch",
                                "Integrated expects explicit sync/latency cues.")
                else:
                    res, det = "Match", "Both sides present."
        else:
            required = a_has and b_has and ab_has
            if not required:
                res, det = "Missing", "Embedded requires A, B, and AB to declare this."
            else:
                text = _join_nonempty(av, bv, abv)
                ok_sync = _has_any(text, _SYNC_TOKENS) if needs_sync_tokens else True
                ok_lat  = _has_any(text, _LOWLAT_TOKENS) if needs_lowlat else True
                ok = ok_sync and ok_lat
                res, det = ("Match" if ok else "Mismatch",
                            "Embedded requires synchronous/low-latency cues (as applicable).")

        rows.append(row(group, label, key, pattern, "Pattern-graded requirement", av, bv, abv, det, res))

    # parallel_execution: stricter in Integrated/Embedded (expect explicit parallel intent)
    eval_presence("Parallel Execution Incompatibility", "parallel_execution")
    # execution_constraints: require sync tokens for Integrated/Embedded
    eval_presence("Execution Constraint Mismatch", "execution_constraints", needs_sync_tokens=True)
    # acknowledgment protocols: presence escalates; content cues not enforced here
    eval_presence("Acknowledgment Protocol Mismatch", "acknowledgment_protocols")
    # latency: expect low-latency cues for Integrated/Embedded
    eval_presence("Latency Expectation Mismatch", "latency_expectations", needs_lowlat=True)

    # data_synchronization is often pivotal: treat like constraints (sync cues)
    key = "data_synchronization"
    av = "; ".join(a.fields.get(key, []))
    bv = "; ".join(b.fields.get(key, []))
    abv = "; ".join((ab.fields.get(key, []) if ab else []))
    a_has, b_has, ab_has = _presence(av, bv, abv)

    if lvl == 1:
        res, det = "Match", "Not required for One-Way."
    elif lvl == 2:
        ok = a_has or b_has or ab_has
        res, det = ("Match" if ok else "Missing", "Loose requires at least one declaration of synchronization.")
    elif lvl == 3:
        ok = a_has and b_has
        res, det = ("Match" if ok else "Missing", "Shared requires A and B to declare synchronization.")
    elif lvl == 4:
        if not (a_has and b_has):
            res, det = "Missing", "Integrated requires A and B synchronization metadata."
        else:
            ok_sync = _has_any(_join_nonempty(av, bv, abv), _SYNC_TOKENS)
            res, det = ("Match" if ok_sync else "Mismatch", "Integrated expects explicit synchronous/lockstep cues.")
    else:
        required = a_has and b_has and ab_has
        if not required:
            res, det = "Missing", "Embedded requires A, B, and AB synchronization metadata."
        else:
            ok_sync = _has_any(_join_nonempty(av, bv, abv), _SYNC_TOKENS)
            res, det = ("Match" if ok_sync else "Mismatch", "Embedded expects explicit synchronous/lockstep cues.")
    rows.append(row(group, "Data Synchronization", key, pattern,
                    "Pattern-graded requirement", av, bv, abv, det, res))

    return rows
# ======================== TECHNOLOGY (hardness increases by pattern) ========================

def check_technology(group: str, a: ModelMeta, b: ModelMeta, ab: Optional[ModelMeta], pattern: str) -> List[Dict[str,Any]]:
    rows: List[Dict[str,Any]] = []
    lvl = _pattern_level(pattern)

    # similarity thresholds escalate with tightness
    TH_SOFT   = 0.00  # any overlap
    TH_MEDIUM = 0.25
    TH_STRONG = 0.50

    def tech_compare(label: str, key: str,
                     exact_from_level: int = 5,
                     strong_from_level: int = 4,
                     required_from_level: int = 2):
        """Pattern-graded comparison for A↔B (and AB if present)."""
        av = "; ".join(a.fields.get(key, []))
        bv = "; ".join(b.fields.get(key, []))
        abv = "; ".join((ab.fields.get(key, []) if ab else []))

        # Not required for very loose patterns
        if lvl < required_from_level and not av and not bv:
            rows.append(row(group, label, key, pattern,
                            "Not required at this pattern", av, bv, abv, "Absent but optional for this pattern.", "Match"))
            return

        # presence gating
        if not av and not bv:
            rows.append(row(group, label, key, pattern, "Presence required", av, bv, abv, "Neither provides metadata.", "Missing"))
            return
        if not av or not bv:
            rows.append(row(group, label, key, pattern, "Presence required", av, bv, abv, "Only one side provides metadata.", "Missing"))
            return

        # choose threshold by level
        if lvl >= exact_from_level:
            # exact equality for the strictest patterns
            if av == bv:
                rows.append(row(group, label, key, pattern, "Exact equality required", av, bv, abv, "Equal.", "Match"))
            else:
                rows.append(row(group, label, key, pattern, "Exact equality required", av, bv, abv, "Not equal.", "Mismatch"))
            return

        # similarity required (stronger at higher levels)
        thr = TH_SOFT if lvl <= 2 else (TH_MEDIUM if lvl == 3 else TH_STRONG)
        simAB = jaccard_token_similarity(av, bv)
        ok = simAB > thr

        # AB alignment kicks in for Integrated/Embedded (levels >=4)
        if lvl >= strong_from_level and abv:
            simA = jaccard_token_similarity(av, abv)
            simB = jaccard_token_similarity(bv, abv)
            ok = ok and (simA > TH_MEDIUM) and (simB > TH_MEDIUM)
            det = f"A↔B={simAB:.2f} (> {thr:.2f}), A↔AB={simA:.2f} & B↔AB={simB:.2f} (> {TH_MEDIUM:.2f})"
        else:
            det = f"A↔B token-sim={simAB:.2f} (> {thr:.2f})"

        rows.append(row(group, label, key, pattern,
                        "Pattern-graded similarity/equality", av, bv, abv, det, "Match" if ok else "Mismatch"))

    # Programming language: exact only for Embedded
    tech_compare("Programming Language Incompatibility", "programming_language",
                 exact_from_level=5, strong_from_level=4, required_from_level=2)

    # Source code availability & Implementation verification: escalate presence expectations
    def per_component_presence(label: str, key: str, who: str, required_from_level: int):
        vv = "; ".join((a if who == "A" else b).fields.get(key, []))
        # L1 One-Way: only A strictly required
        if _pattern_level(pattern) == 1 and who == "B":
            rows.append(row(group, label, f"{key} ({who})", pattern,
                            "Optional for One-Way (B)", vv, "", "", "Optional for B in One-Way.", "Match"))
            return
        # generally required from 'required_from_level'
        if _pattern_level(pattern) < required_from_level and not vv:
            rows.append(row(group, label, f"{key} ({who})", pattern,
                            "Optional at this pattern", vv, "", "", "Optional.", "Match"))
            return
        rows.append(row(group, label, f"{key} ({who})", pattern,
                        "Presence required", vv, "", "", f"{who} provides metadata",
                        "Match" if vv else "Missing"))

    per_component_presence("Source Code Availability Gap", "availability_of_source_code", "A", required_from_level=2)
    per_component_presence("Source Code Availability Gap", "availability_of_source_code", "B", required_from_level=3)
    per_component_presence("Implementation Verification Gap", "implementation_verification", "A", required_from_level=2)
    per_component_presence("Implementation Verification Gap", "implementation_verification", "B", required_from_level=3)

    # Software / Hardware / Versions / File formats: escalate similarity → equality
    tech_compare("Software Environment Mismatch", "software_specification_and_requirements",
                 exact_from_level=5, strong_from_level=4, required_from_level=2)
    tech_compare("Hardware Resource Mismatch", "hardware_specification_and_requirements",
                 exact_from_level=5, strong_from_level=4, required_from_level=2)
    # Versions: exact for Integrated+Embedded (very sensitive)
    tech_compare("Distribution Version Mismatch", "distribution_version",
                 exact_from_level=4, strong_from_level=4, required_from_level=2)
    # File formats: exact for Embedded
    tech_compare("File Format Mismatch", "file_formats",
                 exact_from_level=5, strong_from_level=4, required_from_level=2)

    # License: presence escalates; similarity threshold escalates; exact only at Embedded
    key = "license"
    av = "; ".join(a.fields.get(key, []))
    bv = "; ".join(b.fields.get(key, []))
    if lvl < 2 and not av and not bv:
        rows.append(row(group, "License Incompatibility", key, pattern,
                        "Optional at One-Way", av, bv, "", "Absent but optional.", "Match"))
    else:
        if not av and not bv:
            det, res = "Neither provides license.", "Missing"
        elif not av or not bv:
            det, res = "Only one provides license.", "Missing"
        else:
            if lvl >= 5:
                res = "Match" if av == bv else "Mismatch"
                det = "Exact equality required at Embedded."
            else:
                thr = 0.0 if lvl <= 2 else (0.25 if lvl == 3 else 0.50)
                sim = jaccard_token_similarity(av, bv)
                res = "Match" if sim > thr else "Mismatch"
                det = f"A↔B token-sim={sim:.2f} (> {thr:.2f})"
        rows.append(row(group, "License Incompatibility", key, pattern,
                        "Pattern-graded requirement", av, bv, "", det, res))

    # Landing page: escalate presence (A required from Loose; B required from Shared+)
    def landing_required(who: str) -> int:
        # A: required from level 2; B: from level 3
        return 2 if who == "A" else 3

    for who, model in (("A", a), ("B", b)):
        key = "landing_page"
        vv = "; ".join(model.fields.get(key, []))
        req_from = landing_required(who)
        if lvl < req_from and not vv:
            rows.append(row(group, "Landing Page Gap", f"{key} ({who})", pattern,
                            "Optional at this pattern", vv, "", "", "Optional.", "Match"))
        else:
            rows.append(row(group, "Landing Page Gap", f"{key} ({who})", pattern,
                            "Presence required", vv, "", "", f"{who} provides landing page",
                            "Match" if vv else "Missing"))

    return rows

# ============================================================
# Group evaluation
# ============================================================

def evaluate_group(gid: str, A: ModelMeta, B: ModelMeta, AB: Optional[ModelMeta], debug: bool=False) -> List[Dict[str,Any]]:
    pattern, pr = detect_integration_pattern(A, B, AB)
    if debug:
        print(f"[GROUP {gid}] inferred pattern: {pattern} | {pr}")
    rows: List[Dict[str,Any]] = []
    rows += check_semantic_mismatch(gid, A, B, AB, pattern)
    rows += check_conceptual_quality_gap(gid, A, B, AB, pattern)
    rows += check_information_viewpoint(gid, A, B, AB, pattern)
    rows += check_computational(gid, A, B, AB, pattern)
    rows += check_engineering(gid, A, B, AB, pattern)
    rows += check_technology(gid, A, B, AB, pattern)
    return rows

# ============================================================
# Figures (updated to two groups + requested pies)
# ============================================================

def wilson_ci(k: int, n: int) -> Tuple[float, float]:
    if n == 0:
        return (0.0, 0.0)
    from math import sqrt
    z = 1.96
    p = k / n
    den = 1 + z*z/n
    center = (p + z*z/(2*n)) / den
    half = z * sqrt(p*(1-p)/n + z*z/(4*n*n)) / den
    return max(0.0, center - half), min(1.0, center + half)

def ensure_fig_dir(dirname: str = "figs") -> str:
    if not os.path.isdir(dirname):
        os.makedirs(dirname, exist_ok=True)
    return dirname


def pie_percent(series: pd.Series, title: str, outpath: str, colors: Optional[List[str]] = None):
    import textwrap
    if series.empty or series.sum() == 0:
        return
    fig = plt.figure()
    ax = fig.add_subplot(111)
    vals = series.values

    # Wrap long labels to multiple lines
    raw_labels = [str(x) for x in series.index]
    labels = ["\n".join(textwrap.wrap(l, 15)) for l in raw_labels]

    wedges, texts, autotexts = ax.pie(
        vals,
        labels=labels,
        autopct=lambda p: f"{p:.1f}%",
        colors=(colors[:len(vals)] if colors is not None else None)
    )

    # Smaller fonts so wrapped text fits better
    for t in texts:
        t.set_fontsize(12)
    for t in autotexts:
        t.set_fontsize(12)

    ax.set_title(title)
    fig.tight_layout()
    fig.savefig(outpath, dpi=200, bbox_inches="tight")  # <-- important
    plt.close(fig)


def generate_figures(df: pd.DataFrame) -> None:
    if not HAS_MPL:
        return
    figs_dir = ensure_fig_dir()

    import os
    import numpy as np
    import matplotlib.pyplot as plt

    figs_dir = ensure_fig_dir()

    if "ab_kind" not in df.columns:
        print("Validation figs skipped: no 'ab_kind' column in df")
        return

    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns

    def viewpoint_of(bottleneck: str) -> str:
        # Example placeholder — replace with your actual mapping
        return bottleneck_viewpoint(bottleneck)

    # --- MAIN PLOT SECTION ---
    KEY = ["group", "bottleneck", "field"]

    intended = df[df["ab_kind"] == "INTENDED"].copy()
    integrated = df[df["ab_kind"] == "INTEGRATED"].copy()

    intended_mism = intended[intended["result"].str.lower() == "mismatch"]

    if intended_mism.empty:
        print("No INTENDED mismatches to validate.")
    else:
        mm = intended_mism.merge(
            integrated[KEY + ["result"]],
            on=KEY,
            how="left",
            suffixes=("_INT", "_INTG")
        )

        mm["_aligned"] = (mm["result_INTG"].str.lower() == "mismatch")

        # --- COLORS ---
        COLORS = {
            True: "#4daf4a",  # aligned → green
            False: "#e41a1c"  # incorrect → red
        }

        sns.set_theme(style="white")  # clean background, no grid
        plt.rcParams.update({
            "font.size": 13,
            "axes.titlesize": 15,
            "axes.labelsize": 14,
            "figure.dpi": 300,
            "savefig.dpi": 300
        })

        # --- Figure 1: Overall ---
        counts_overall = mm["_aligned"].value_counts().reindex([True, False], fill_value=0)
        labels = ["True Detection", "False Detection"]
        values = [int(counts_overall.get(True, 0)), int(counts_overall.get(False, 0))]
        colors = [COLORS[True], COLORS[False]]

        fig, ax = plt.subplots(figsize=(6, 4))
        bars = ax.bar(labels, values, color=colors, edgecolor="white", width=0.6)

        # Add value labels on top
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2, height + max(values) * 0.02,
                    f"{int(height)}", ha="center", va="bottom", fontsize=12, weight="bold")

        ax.set_ylabel("Count", fontsize=13, weight="bold")
        ax.set_xlabel("")
        ax.set_title("Validation Against Realized Integrations", fontsize=15, weight="bold", pad=10)
        sns.despine(left=True, bottom=True)
        ax.grid(False)

        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "validation_overall.png"), bbox_inches="tight", dpi=300)
        plt.close(fig)

        # --- Figure 2: By RM-ODP Viewpoint ---
        mm["_viewpoint"] = mm["bottleneck"].apply(viewpoint_of)
        piv = (mm.groupby("_viewpoint")["_aligned"]
               .value_counts()
               .unstack(fill_value=0)
               .reindex(columns=[True, False], fill_value=0))

        if not piv.empty:
            fig, ax = plt.subplots(figsize=(8, 5))
            idx = np.arange(len(piv.index))

            # Bar colors
            ax.bar(idx, piv[True].values, color=COLORS[True], label="True Detection", width=0.6, edgecolor="white")
            ax.bar(idx, piv[False].values, bottom=piv[True].values,
                   color=COLORS[False], label="False Detection", width=0.6, edgecolor="white")

            # Axis setup
            ax.set_xticks(idx)
            ax.set_xticklabels(piv.index, rotation=16, ha="right", fontsize=12)
            ax.set_ylabel("Number of Detected Mismatches (by Detector)", fontsize=12, weight="bold")
            ax.set_xlabel("")
            ax.set_title("", fontsize=15, weight="bold", pad=10)
            ax.legend(fontsize=16, frameon=False, loc="upper right")

            # Total value annotations
            for i, (a, b) in enumerate(zip(piv[True], piv[False])):
                total = a + b
                ax.text(i, total + max(piv.sum(axis=1)) * 0.02, f"{total}",
                        ha="center", va="bottom", fontsize=11)

            # ---- Clean but visible axis lines ----
            sns.despine(left=False, bottom=False)  # keep both x and y visible
            ax.spines["bottom"].set_color("black")
            ax.spines["left"].set_color("black")
            ax.spines["bottom"].set_linewidth(1.2)
            ax.spines["left"].set_linewidth(1.2)

            # Remove top/right borders
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)

            # No gridlines
            ax.grid(False)

            fig.tight_layout()
            fig.savefig(os.path.join(figs_dir, "validation_by_viewpoint.png"),
                        bbox_inches="tight", dpi=300)
            plt.close(fig)

        print("✅ Saved validation figures in figs/:")
        print(" - validation_overall.png")
        print(" - validation_by_viewpoint.png")

    # --- define remap/merge/remove rules once, available everywhere ---
    def remap_field(f: str) -> Optional[str]:
        if f in {"file_formats", "(A or B).input vs AB.input", "A.input vs AB.input"}:
            return "Input mismatch"
        if f == "communication_mechanism":
            return None  # remove
        if f == "model_version":
            return None  # remove
        if f == "distribution_version":
            return None  # remove
        if f.startswith("availability_of_source_code"):
            return "Availability of source code"
        if f.startswith("landing_page"):
            return "Landing page"
        if f in {"B.output vs AB.output", "(A or B).output vs AB.output"}:
            return "Output"
        if f == "Direction (any)":
            return None  # remove
        return f  # keep others unchanged

    # ---------- canonical colors & orders ----------
    # softer, print-friendly palette
    COLORS = {
        "Match": "#4CAF50",  # professional green
        "Mismatch": "#E57373",  # soft red
        "Metadata Gap": "#FFB74D"  # orange
    }
    # softer categorical palette for arbitrary categories (patterns, fields, bottlenecks, etc.)
    SOFT_CMAP = [
        "#A6CEE3", "#B2DF8A", "#FB9A99", "#FDBF6F", "#CAB2D6",
        "#FFFF99", "#1F78B4", "#33A02C", "#E31A1C", "#FF7F00",
        "#6A3D9A", "#B15928", "#CCEBC5", "#FFED6F", "#B3CDE3",
        "#FBB4AE", "#DECBE4", "#FED9A6", "#FFFFCC", "#E5D8BD",
        "#FDDAEC", "#F2F2F2", "#80B1D3", "#B3DE69", "#FCCDE5",
        "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F", "#8DD3C7",
        "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462",
        "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5",
        "#FFED6F", "#FFB3A2", "#A0CBE8", "#FFD92F", "#E5C494",
        "#B3B3B3"
    ]
    import matplotlib
    plt.rcParams["axes.prop_cycle"] = matplotlib.cycler(color=SOFT_CMAP)
    ORDER2 = ["Mismatch", "Metadata Gap"]
    ORDER3 = ["Match", "Mismatch", "Metadata Gap"]
    VP_ORDER = ["Domain", "Information", "Computational", "Engineering", "Technology"]
    #PATTERNS = ["One-Way", "Loose", "Shared", "Integrated", "Embedded", "(unspecified)"]
    PATTERNS = ["One-Way", "Loose", "Shared", "Integrated", "Embedded"]


    # ---------- helpers ----------
    def pie_percent(series: pd.Series, title: str, outpath: str, colors: Optional[List[str]] = None):
        if series.empty or series.sum() == 0:
            return
        fig = plt.figure()
        ax = fig.add_subplot(111)
        vals = series.values
        labels = series.index.tolist()
        if colors is None:
            ax.pie(vals, labels=labels, autopct=lambda p: f"{p:.1f}%")
        else:
            # truncate/align colors with labels length
            ax.pie(vals, labels=labels, autopct=lambda p: f"{p:.1f}%", colors=colors[:len(vals)])
        ax.set_title(title)
        fig.subplots_adjust(wspace=0.25, hspace=0.35)

        fig.tight_layout()
        fig.savefig(outpath, dpi=200)
        plt.close(fig)

    def stacked_bars(ax, piv: pd.DataFrame, order: List[str]):
        """Draw stacked bars in fixed color order."""
        idx = np.arange(len(piv.index))
        bottoms = np.zeros(len(idx))
        for col in order:
            vals = piv[col].values if col in piv.columns else np.zeros(len(idx))
            ax.bar(idx, vals, bottom=bottoms, label=col, color=COLORS.get(col))
            bottoms += vals
        ax.set_xticks(idx)
        ax.set_xticklabels(piv.index, rotation=0)

    def nice_ceil(x: float, step: int = 5) -> int:
        if x <= 0:
            return 1
        return int(np.ceil(x / step) * step)

    # ---------- derived labels ----------
    df["_viewpoint"] = df["bottleneck"].apply(bottleneck_viewpoint)
    df["_pattern"] = df["pattern"].fillna("(unspecified)").replace("", "(unspecified)")
    df["_is_mismatch"] = df["result"].str.lower().eq("mismatch")
    df["_is_gap"] = df["result"].str.lower().eq("missing")
    df["_is_problem"] = df["_is_mismatch"] | df["_is_gap"]
    df["_group"] = df.apply(
        lambda r: "Mismatch" if r["_is_mismatch"] else ("Metadata Gap" if r["_is_gap"] else "OK"), axis=1)
    df["_plot_group3"] = df["_group"].replace({"OK": "Match"})

    # ---------- 1) Overall detection rate (with 95% Wilson CI) ----------
    grp_any = df.groupby("group")["_is_problem"].any()
    n_cfg = int(len(grp_any)) if len(grp_any) else 0
    k_cfg = int(grp_any.sum()) if len(grp_any) else 0
    p_hat = (k_cfg / n_cfg) if n_cfg else 0.0
    lo, hi = wilson_ci(k_cfg, n_cfg) if n_cfg else (0.0, 0.0)
    err_low, err_high = p_hat - lo, hi - p_hat

    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.bar([0], [p_hat], color="#88AADD")  # neutral color
    ax.errorbar([0], [p_hat], yerr=[[err_low], [err_high]], fmt="o", capsize=5)
    ax.set_ylim(0, 1)
    ax.set_xticks([0])
    ax.set_xticklabels(["Detection rate"])
    ax.set_ylabel("Share of configurations")
    ax.set_title(f"Overall detection rate (n={n_cfg}, 95% Wilson CI)")
    fig.tight_layout()
    fig.savefig(os.path.join(figs_dir, "overall_detection_rate.png"), dpi=200)
    plt.close(fig)

    # ---------- 2) Viewpoint × group (problems only; stacked) ----------
    pivot_counts = (df[df["_is_problem"]]
                    .groupby(["_viewpoint", "_group"])
                    .size()
                    .unstack(fill_value=0)
                    .reindex(index=VP_ORDER, fill_value=0)
                    .reindex(columns=ORDER2, fill_value=0))
    if not pivot_counts.empty:
        fig = plt.figure()
        ax = fig.add_subplot(111)
        stacked_bars(ax, pivot_counts, ORDER2)
        ax.set_ylabel("Problem count")
        ax.set_title("Bottlenecks by RM-ODP viewpoint × group")
        ax.legend()
        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "viewpoint_by_group_stacked.png"), dpi=200)
        plt.close(fig)

    # ---------- 3) Pattern sensitivity heatmap (pattern × group) ----------
    heat = (df[df["_is_problem"]]
            .groupby(["_pattern", "_group"])
            .size()
            .unstack(fill_value=0)
            .reindex(index=PATTERNS, fill_value=0)
            .reindex(columns=ORDER2, fill_value=0))
    if not heat.empty:
        fig = plt.figure()
        ax = fig.add_subplot(111)
        im = ax.imshow(heat.values, aspect="auto")
        ax.set_xticks(np.arange(heat.shape[1]))
        ax.set_xticklabels(list(heat.columns))
        ax.set_yticks(np.arange(heat.shape[0]))
        ax.set_yticklabels(list(heat.index))
        ax.set_title("Pattern sensitivity: problems by pattern × group")
        for i in range(heat.shape[0]):
            for j in range(heat.shape[1]):
                ax.text(j, i, str(int(heat.values[i, j])), ha="center", va="center")
        fig.colorbar(im, ax=ax)
        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "pattern_sensitivity_heatmap.png"), dpi=200)
        plt.close(fig)

    # ---------- 4) Field-level impact (Pareto on problems) ----------
    field_counts = (df[df["_is_problem"]].groupby("field").size().sort_values(ascending=False))
    if not field_counts.empty:
        top_k = min(15, len(field_counts))
        fc = field_counts.iloc[:top_k]
        cum = (fc.cumsum() / fc.sum()) if fc.sum() else fc * 0
        fig = plt.figure()
        ax = fig.add_subplot(111)
        idx = np.arange(len(fc.index))
        ax.bar(idx, fc.values, color="#88AADD")
        ax.set_xticks(idx)
        ax.set_xticklabels(fc.index, rotation=90)
        ax.set_ylabel("Problem count")
        ax.set_title("Field-level impact (Pareto: top-k fields)")
        ax2 = ax.twinx()
        ax2.plot(idx, cum.values, marker="o")
        ax2.set_ylim(0, 1)
        ax2.set_ylabel("Cumulative share")
        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "field_level_pareto.png"), dpi=200)
        plt.close(fig)

    # ---------- 5) Pies: mismatch/gap distributions ----------
    def counts_of(df_sub: pd.DataFrame, col: str) -> pd.Series:
        if df_sub.empty:
            return pd.Series(dtype=int)
        return df_sub.groupby(col).size().sort_values(ascending=False)

    mism = df[df["_is_mismatch"]]
    gaps = df[df["_is_gap"]]

    pie_percent(counts_of(mism, "_viewpoint"), "Mismatch by Viewpoint (%)",
                os.path.join(figs_dir, "pie_mismatch_by_viewpoint.png"),colors=SOFT_CMAP)
    pie_percent(counts_of(gaps, "_viewpoint"), "Metadata Gap by Viewpoint (%)",
                os.path.join(figs_dir, "pie_gap_by_viewpoint.png"),colors=SOFT_CMAP)

    pie_percent(counts_of(mism, "bottleneck"), "Mismatch by Bottleneck (%)",
                os.path.join(figs_dir, "pie_mismatch_by_bottleneck.png"),colors=SOFT_CMAP)
    pie_percent(counts_of(gaps, "bottleneck"), "Metadata Gap by Bottleneck (%)",
                os.path.join(figs_dir, "pie_gap_by_bottleneck.png"),colors=SOFT_CMAP)

    pie_percent(counts_of(mism, "_pattern"), "Mismatch by Integration Pattern (%)",
                os.path.join(figs_dir, "pie_mismatch_by_pattern.png"),colors=SOFT_CMAP)
    pie_percent(counts_of(gaps, "_pattern"), "Metadata Gap by Integration Pattern (%)",
                os.path.join(figs_dir, "pie_gap_by_pattern.png"),colors=SOFT_CMAP)

    pie_percent(counts_of(mism, "field"), "Mismatch by Field (%)",
                os.path.join(figs_dir, "pie_mismatch_by_field.png"),colors=SOFT_CMAP)
    pie_percent(counts_of(gaps, "field"), "Metadata Gap by Field (%)",
                os.path.join(figs_dir, "pie_gap_by_field.png"),colors=SOFT_CMAP)

    # ---------- 6) Facet: viewpoint × group per pattern (UNIFIED Y) ----------
    # pre-compute a global y-limit across panels
    y_max = 0
    pivots = {}
    for pat in PATTERNS:
        sub = df[(df["_pattern"] == pat) & (df["_is_problem"])]
        if sub.empty:
            continue
        piv = (sub.groupby(["_viewpoint", "_group"])
               .size()
               .unstack(fill_value=0)
               .reindex(index=VP_ORDER, fill_value=0)
               .reindex(columns=ORDER2, fill_value=0))
        pivots[pat] = piv
        y_max = max(y_max, int(piv.sum(axis=1).max()) if not piv.empty else 0)
    y_max = nice_ceil(y_max)

    n = len(PATTERNS)
    cols = 3
    rows = int(np.ceil(n / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5.0, rows * 4.0), squeeze=False, sharey=True)
    any_plotted = False
    for i, pat in enumerate(PATTERNS):
        ax = axes[i // cols][i % cols]
        piv = pivots.get(pat)
        if piv is None or piv.empty:
            ax.axis("off")
            ax.set_title(f"{pat} (no problems)")
            continue
        stacked_bars(ax, piv, ORDER2)
        ax.set_ylabel("Count")
        ax.set_title(f"{pat} (n={int(piv.values.sum())})")
        ax.set_ylim(0, max(1, y_max) * 1.10)
        any_plotted = True
    for j in range(len(PATTERNS), rows * cols):
        axes[j // cols][j % cols].axis("off")
    if any_plotted:
        fig.legend(ORDER2, loc="upper center", ncol=2)
        fig.tight_layout(rect=(0, 0, 1, 0.92))
        fig.savefig(os.path.join(figs_dir, "viewpoint_by_group_stacked_by_pattern.png"), dpi=200)
        plt.close(fig)

    # ---------- 7) Facet: per pattern, per-viewpoint Match/Mismatch/Gap (UNIFIED Y) ----------
    y_max3 = 0
    piv3 = {}
    for pat in PATTERNS:
        sub = df[df["_pattern"] == pat]
        if sub.empty:
            continue
        piv = (sub.groupby(["_viewpoint", "_plot_group3"])
               .size()
               .unstack(fill_value=0)
               .reindex(index=VP_ORDER, fill_value=0)
               .reindex(columns=ORDER3, fill_value=0))
        piv3[pat] = piv
        y_max3 = max(y_max3, int(piv.sum(axis=1).max()) if not piv.empty else 0)
    y_max3 = nice_ceil(y_max3)

    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5.2, rows * 4.2), squeeze=False, sharey=True)
    any_plotted = False
    for i, pat in enumerate(PATTERNS):
        ax = axes[i // cols][i % cols]
        piv = piv3.get(pat)
        if piv is None or piv.empty:
            ax.axis("off")
            ax.set_title(f"{pat} (no rows)")
            continue
        idx = np.arange(len(piv.index))
        bottoms = np.zeros(len(idx))
        for col in ORDER3:
            ax.bar(idx, piv[col].values, bottom=bottoms, label=col, color=COLORS[col])
            bottoms += piv[col].values
        ax.set_xticks(idx)
        ax.set_xticklabels(piv.index, rotation=45, ha="right")
        ax.set_ylabel("Count")
        ax.set_title(f"{pat} (n={int(piv.values.sum())})")
        ax.set_ylim(0, max(1, y_max3) * 1.10)
        any_plotted = True
    for j in range(len(PATTERNS), rows * cols):
        axes[j // cols][j % cols].axis("off")
    if any_plotted:
        fig.legend(ORDER3, loc="upper center", ncol=3)
        fig.tight_layout(rect=(0, 0, 1, 0.92))
        fig.savefig(os.path.join(figs_dir, "viewpoint_match_mismatch_gap_by_pattern.png"), dpi=200)
        plt.close(fig)

    # ---------- 8) Single chart: per-viewpoint Match/Mismatch/Gap ----------
    piv_vp = (df.groupby(["_viewpoint", "_plot_group3"])
              .size()
              .unstack(fill_value=0)
              .reindex(index=VP_ORDER, fill_value=0)
              .reindex(columns=ORDER3, fill_value=0))
    if not piv_vp.empty:
        fig = plt.figure()
        ax = fig.add_subplot(111)
        idx = np.arange(len(piv_vp.index))
        bottoms = np.zeros(len(idx))
        for col in ORDER3:
            ax.bar(idx, piv_vp[col].values, bottom=bottoms, label=col, color=COLORS[col])
            bottoms += piv_vp[col].values
        ax.set_xticks(idx)
        ax.set_xticklabels(piv_vp.index, rotation=0)
        ax.set_ylabel("Count")
        ax.set_title("Per-viewpoint: Match vs Mismatch vs Metadata Gap")
        ax.legend()
        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "viewpoint_match_mismatch_gap.png"), dpi=200)
        plt.close(fig)

    # ---------- 9) For each pattern: % Match / % Mismatch / % Metadata Gap (pie) ----------
    n = len(PATTERNS)
    cols = 3
    rows = int(np.ceil(n / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5.0, rows * 4.5), squeeze=False)

    for i, pat in enumerate(PATTERNS):
        ax = axes[i // cols][i % cols]
        sub = df[df["_pattern"] == pat]
        if sub.empty:
            ax.axis("off")
            ax.set_title(f"{pat} (no rows)")
            continue

        counts = (sub["_plot_group3"].value_counts().reindex(ORDER3, fill_value=0))
        total = counts.sum()
        if total == 0:
            ax.axis("off")
            ax.set_title(f"{pat} (no rows)")
            continue

        ax.pie(counts.values,
               labels=counts.index,
               autopct=lambda p: f"{p:.1f}%",
               colors=[COLORS[k] for k in ORDER3])
        ax.set_title(f"{pat} (n={int(total)})")

    for j in range(len(PATTERNS), rows * cols):
        axes[j // cols][j % cols].axis("off")

    fig.tight_layout()
    fig.savefig(os.path.join(figs_dir, "pie_match_mismatch_gap_by_pattern.png"), dpi=200)
    plt.close(fig)
    # --- NEW: mismatch-by-bottleneck pie with <4% grouped into "Other" ---
    def pie_percent_collapse_other(series: pd.Series, title: str, outpath: str, min_pct: float = 0.04):
        """Collapse categories whose share < min_pct into a single 'Other' slice."""
        if series.empty or series.sum() == 0:
            return
        series = series.sort_values(ascending=False)
        total = float(series.sum())
        pct = series / total
        small_mask = pct < min_pct
        other_count = series[small_mask].sum()
        series2 = series[~small_mask].copy()
        if other_count > 0:
            series2.loc["Other"] = other_count
            # keep 'Other' as the last slice for readability
            order = [i for i in series2.index if i != "Other"] + ["Other"]
            series2 = series2.reindex(order)
        # Reuse the existing pie helper
        pie_percent(series2, title, outpath)

    pie_percent_collapse_other(
        counts_of(mism, "bottleneck"),
        "Mismatch by Bottleneck (%) — small slices (<4%) grouped as Other",
        os.path.join(figs_dir, "pie_mismatch_by_bottleneck_other.png"),
        min_pct=0.04
    )

    def pie_percent_collapse_other(series: pd.Series, title: str, outpath: str, min_pct: float = 0.04):
        """
        Creates a publication-quality horizontal bar chart of category percentages,
        collapsing small categories (<min_pct) into 'Other'.

        Parameters
        ----------
        series : pd.Series
            Counts by category.
        title : str
            Chart title.
        outpath : str
            Path to save PNG/PDF figure.
        min_pct : float
            Minimum share threshold for retaining a category (default=0.04 → 4%).
        """
        import matplotlib.pyplot as plt
        import seaborn as sns
        import numpy as np

        # --- Safety check ---
        if series.empty or series.sum() == 0:
            print("⚠️ Warning: Empty or zero-sum data, no chart created.")
            return

        # --- Collapse small categories into "Other" ---
        series = series.sort_values(ascending=False)
        total = float(series.sum())
        pct = series / total
        small_mask = pct < min_pct
        other_count = series[small_mask].sum()

        series2 = series[~small_mask].copy()
        if other_count > 0:
            series2.loc["Other"] = other_count
            order = [i for i in series2.index if i != "Other"] + ["Other"]
            series2 = series2.reindex(order)

        # --- Normalize to percentages ---
        pct_series = (series2 / series2.sum()) * 100

        # --- Professional color palette (ColorBrewer Set2 – colorblind safe) ---
        COLORS_BOTTLENECK = [
            "#66c2a5",  # soft green
            "#fc8d62",  # coral
            "#8da0cb",  # soft blue
            "#e78ac3",  # pink/magenta
            "#a6d854",  # lime green
            "#ffd92f",  # amber/yellow
            "#e5c494",  # beige
            "#b3b3b3"  # gray for 'Other'
        ]
        colors = COLORS_BOTTLENECK[:len(pct_series)]

        # --- Plot setup ---
        sns.set_style("whitegrid")
        fig, ax = plt.subplots(figsize=(7, 5))
        bars = ax.barh(
            pct_series.index[::-1],
            pct_series.values[::-1],
            color=colors[::-1],
            edgecolor="white"
        )

        # --- Add percentage labels on bars ---
        for bar, value in zip(bars, pct_series.values[::-1]):
            ax.text(
                value + 0.5,
                bar.get_y() + bar.get_height() / 2,
                f"{value:.1f}%",
                va="center",
                fontsize=12
            )

        # --- Axis labels and formatting ---
        ax.set_xlabel("Percentage (%)", fontsize=13, weight="bold")
        ax.set_ylabel("")
        ax.set_xlim(0, pct_series.max() * 1.25)
        ax.set_title(title, fontsize=15, weight="bold", pad=10)
        ax.tick_params(axis="y", labelsize=12)
        ax.grid(axis="x", linestyle="--", alpha=0.6)
        sns.despine(left=True, bottom=True)

        # --- Final layout and save ---
        plt.tight_layout()
        fig.savefig(outpath, dpi=300, bbox_inches="tight")
        plt.close(fig)
        print(f"✅ Saved bar chart to: {outpath}")

    # ----------------------------------------------------------------------
    # ✅ Call the function (same as before)
    # ----------------------------------------------------------------------
    pie_percent_collapse_other(
        counts_of(mism, "bottleneck"),
        "Mismatch by Bottleneck (%) — small slices (<4%) grouped as Other",
        os.path.join(figs_dir, "pie_mismatch_by_bottleneck_other2.png"),
        min_pct=0.04
    )

    import string
    import matplotlib.patches as mpatches

    # ---------- Pattern pies WITHOUT labels ----------
    # One pie per integration pattern; slices = [Match, Mismatch, Metadata Gap]; only % shown.
    n = len(PATTERNS)
    cols = 3
    rows = int(np.ceil(n / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6.0, rows * 5.5), squeeze=False)

    for i, pat in enumerate(PATTERNS):
        ax = axes[i // cols][i % cols]
        sub = df[df["_pattern"] == pat]

        if sub.empty:
            ax.axis("off")
            continue

        counts = sub["_plot_group3"].value_counts().reindex(ORDER3, fill_value=0)
        total = counts.sum()

        if total == 0:
            ax.axis("off")
            continue

        wedges, texts, autotexts = ax.pie(
            counts.values,
            labels=None,  # no slice labels
            autopct=lambda p: f"{p:.1f}%",  # show only %
            colors=[COLORS[k] for k in ORDER3],
            textprops={"fontsize": 16, "weight": "bold"}
        )

        # Format percentages
        for t in autotexts:
            t.set_fontsize(16)
            t.set_weight("bold")

        # Title BELOW each pie (close distance)
        ax.text(
            0.5, -0.07, f"{string.ascii_lowercase[i]}) {pat}",
            transform=ax.transAxes,
            ha="center", va="top",
            fontsize=16, weight="bold"
        )

    # Create legend
    handles = [
        mpatches.Patch(color=COLORS["Match"], label="Match"),
        mpatches.Patch(color=COLORS["Mismatch"], label="Mismatch"),
        mpatches.Patch(color=COLORS["Metadata Gap"], label="Metadata Gap"),
    ]

    # Use empty slot for legend if available
    if len(PATTERNS) < rows * cols:
        ax_legend = axes[len(PATTERNS) // cols][len(PATTERNS) % cols]
        ax_legend.axis("off")
        ax_legend.legend(
            handles=handles,
            loc="center",
            frameon=True,
            fancybox=True,
            fontsize=16,
            title="Categories",
            title_fontsize=20
        )

    # Turn off unused subplot cells
    for j in range(len(PATTERNS) + 1, rows * cols):
        axes[j // cols][j % cols].axis("off")

    fig.tight_layout()
    fig.savefig(
        os.path.join(figs_dir, "pie_match_mismatch_gap_by_pattern_nolabels.png"),
        dpi=300,
        bbox_inches="tight"
    )
    plt.close(fig)



    #new:

    def pie_percent_collapse_other(series: pd.Series, title: str, outpath: str, min_pct: float = 0.04):
        """
        Creates a publication-quality pie chart of category percentages,
        collapsing small categories (<min_pct) into 'Other'.

        Parameters
        ----------
        series : pd.Series
            Counts by category.
        title : str
            Chart title.
        outpath : str
            Path to save PNG/PDF figure.
        min_pct : float
            Minimum share threshold for retaining a category (default=0.04 → 4%).
        """
        import matplotlib.pyplot as plt
        import seaborn as sns
        import numpy as np

        # --- Safety check ---
        if series.empty or series.sum() == 0:
            print("⚠️ Warning: Empty or zero-sum data, no chart created.")
            return

        # --- Collapse small categories into "Other" ---
        series = series.sort_values(ascending=False)
        total = float(series.sum())
        pct = series / total
        small_mask = pct < min_pct
        other_count = series[small_mask].sum()

        series2 = series[~small_mask].copy()
        if other_count > 0:
            series2.loc["Other"] = other_count
            # Keep 'Other' as the last slice
            order = [i for i in series2.index if i != "Other"] + ["Other"]
            series2 = series2.reindex(order)

        # --- Professional color palette (ColorBrewer Set2 – colorblind-safe) ---
        COLORS_BOTTLENECK = [
            "#66c2a5",  # soft green
            "#fc8d62",  # coral
            "#8da0cb",  # soft blue
            "#e78ac3",  # pink/magenta
            "#a6d854",  # lime green
            "#ffd92f",  # amber/yellow
            "#e5c494",  # beige
            "#b3b3b3"  # gray for 'Other'
        ]
        colors = COLORS_BOTTLENECK[:len(series2)]

        # --- Compute percentages for labels ---
        pct_series = (series2 / series2.sum()) * 100

        # --- Plot setup ---
        sns.set_style("white")
        fig, ax = plt.subplots(figsize=(6, 6))

        wedges, texts, autotexts = ax.pie(
            pct_series,
            labels=series2.index,
            autopct=lambda p: f"{p:.1f}%",
            startangle=90,
            colors=colors,
            wedgeprops=dict(edgecolor="white", linewidth=1.5),
            textprops={"fontsize": 12, "color": "black"},
            pctdistance=0.8,
        )

        # --- Styling and title ---
        plt.setp(autotexts, size=12, weight="bold", color="black")
        ax.set_title(title, fontsize=15, weight="bold", pad=20)
        ax.axis("equal")  # equal aspect ratio for perfect circle
        plt.tight_layout()

        # --- Save high-quality figure ---
        fig.savefig(outpath, dpi=300, bbox_inches="tight", facecolor="white")
        plt.close(fig)
        print(f"✅ Saved improved pie chart to: {outpath}")

    pie_percent_collapse_other(
        counts_of(mism, "bottleneck"),
        "Mismatch by Bottleneck (%) — small slices (<4%) grouped as Other",
        os.path.join(figs_dir, "pie_mismatch_by_bottleneck_other3.png"),
        min_pct=0.04
    )

    # ---------- NEW: Global color guidance (single legend image) ----------
    import matplotlib.patches as mpatches
    fig = plt.figure(figsize=(5.2, 1.3))
    ax = fig.add_subplot(111)
    ax.axis("off")
    handles = [
        mpatches.Patch(color=COLORS["Match"], label="Match"),
        mpatches.Patch(color=COLORS["Mismatch"], label="Mismatch"),
        mpatches.Patch(color=COLORS["Metadata Gap"], label="Metadata Gap"),
    ]
    # Centered, no frame, one row
    leg = ax.legend(handles=handles, loc="center", ncol=3, frameon=False, title="Color guide")
    fig.tight_layout()
    fig.savefig(os.path.join(figs_dir, "color_guide_match_mismatch_gap.png"), dpi=200)
    plt.close(fig)
    # ---------- NEW: For each viewpoint, normalized (by n_vp) stacked bars across patterns ----------
    # Each panel = one viewpoint; x = patterns; bars = [Match, Mismatch, Metadata Gap] / n_vp  ∈ [0,1]
    views = VP_ORDER  # ["Domain","Information","Computational","Engineering","Technology"]
    n_v = len(views)
    cols = 2
    rows = int(np.ceil(n_v / cols))

    fig, axes = plt.subplots(rows, cols, figsize=(cols * 6.0, rows * 4.6), squeeze=False, sharey=True)

    for i, vp in enumerate(views):
        ax = axes[i // cols][i % cols]
        sub = df[df["_viewpoint"] == vp]
        n_total = int(sub.shape[0])

        if n_total == 0:
            ax.axis("off")
            ax.set_title(f"{vp} (no rows)")
            continue

        piv = (sub.groupby(["_pattern", "_plot_group3"])
                   .size()
                   .unstack(fill_value=0)
                   .reindex(index=PATTERNS, fill_value=0)      # ["One-Way","Loose","Shared","Integrated","Embedded","(unspecified)"]
                   .reindex(columns=ORDER3, fill_value=0))     # ["Match","Mismatch","Metadata Gap"]

        piv_norm = piv / float(n_total)  # <-- normalize by viewpoint total (e.g., 44) to get shares in [0,1]

        idx = np.arange(len(piv_norm.index))
        bottoms = np.zeros(len(idx))
        for col in ORDER3:
            ax.bar(idx, piv_norm[col].values, bottom=bottoms, color=COLORS[col])
            bottoms += piv_norm[col].values

        ax.set_xticks(idx)
        ax.set_xticklabels(piv_norm.index, rotation=45, ha="right")
        ax.set_ylim(0, 1.0)
        ax.set_ylabel("Share of viewpoint rows")
        ax.set_title(f"{vp} (n={n_total})")

    # turn off any extra empty subplots
    for j in range(n_v, rows * cols):
        axes[j // cols][j % cols].axis("off")

    # single legend for the whole grid (colors already established globally)
    fig.legend(ORDER3, loc="upper center", ncol=3, frameon=False)
    fig.tight_layout(rect=(0, 0, 1, 0.92))
    fig.savefig(os.path.join(figs_dir, "viewpoint_by_pattern_normalized.png"), dpi=200)
    plt.close(fig)
    import string
    import matplotlib.patches as mpatches

    # ---------- Per-viewpoint distribution within each pattern (shares sum to 1) ----------
    # For each viewpoint, show across patterns the share of Match/Mismatch/Metadata Gap **within** each pattern.
    views = VP_ORDER  # ["Domain","Information","Computational","Engineering","Technology"]
    n_v = len(views)
    cols = 2
    rows = int(np.ceil(n_v / cols))

    fig, axes = plt.subplots(rows, cols, figsize=(cols * 7.0, rows * 5.5), squeeze=False, sharey=True)

    for i, vp in enumerate(views):
        ax = axes[i // cols][i % cols]
        sub = df[df["_viewpoint"] == vp]

        if sub.empty:
            ax.axis("off")
            continue

        # counts per (pattern, result-class)
        piv = (
            sub.groupby(["_pattern", "_plot_group3"])
            .size()
            .unstack(fill_value=0)
            .reindex(index=PATTERNS, fill_value=0)  # keep consistent pattern order
            .reindex(columns=ORDER3, fill_value=0)  # ["Match","Mismatch","Metadata Gap"]
        )

        # normalize **within each pattern** so each row sums to 1
        totals = piv.sum(axis=1).replace(0, np.nan)  # avoid div-by-zero
        piv_norm = piv.div(totals, axis=0).fillna(0.0)

        idx = np.arange(len(piv_norm.index))
        bottoms = np.zeros(len(idx))

        for col in ORDER3:  # fixed color mapping, no black border
            ax.bar(idx, piv_norm[col].values, bottom=bottoms, color=COLORS[col])
            bottoms += piv_norm[col].values

        ax.set_xticks(idx)
        ax.set_xticklabels(piv_norm.index, rotation=45, ha="right", fontsize=13)
        ax.set_ylim(0, 1.0)
        ax.set_ylabel("Proportion of Match/Mismatch/Gap", fontsize=14, weight="bold")
        ax.tick_params(axis="y", labelsize=13)

        # Title BELOW each subplot with alphabetic label — slightly more distance
        ax.text(
            0.5, -0.18, f"{string.ascii_lowercase[i]}) {vp}",
            transform=ax.transAxes,
            ha="center", va="top",
            fontsize=15, weight="bold"
        )

    # Legend setup
    handles = [
        mpatches.Patch(color=COLORS["Match"], label="Match"),
        mpatches.Patch(color=COLORS["Mismatch"], label="Mismatch"),
        mpatches.Patch(color=COLORS["Metadata Gap"], label="Metadata Gap"),
    ]

    # If there’s an empty slot, use it for the legend
    if n_v < rows * cols:
        ax_legend = axes[n_v // cols][n_v % cols]
        ax_legend.axis("off")
        ax_legend.legend(
            handles=handles,
            loc="center",
            frameon=True,
            fancybox=True,
            fontsize=15,
            title="Categories",
            title_fontsize=16
        )

    # Turn off any other extra axes beyond the legend slot
    for j in range(n_v + 1, rows * cols):
        axes[j // cols][j % cols].axis("off")

    fig.tight_layout()
    fig.savefig(os.path.join(figs_dir, "viewpoint_by_pattern_distribution.png"), dpi=300, bbox_inches="tight")
    plt.close(fig)

    import string
    import matplotlib.patches as mpatches

    # ---------- Per-viewpoint distribution within each pattern (shares sum to 1) ----------
    # For each viewpoint, show across patterns the share of Match/Mismatch/Metadata Gap **within** each pattern.
    views = VP_ORDER  # ["Domain","Information","Computational","Engineering","Technology"]
    n_v = len(views)
    cols = 2
    rows = int(np.ceil(n_v / cols))

    # ↓ Decrease vertical size (y-axis height) by about half
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 7.0, rows * 3.0), squeeze=False, sharey=True)

    for i, vp in enumerate(views):
        ax = axes[i // cols][i % cols]
        sub = df[df["_viewpoint"] == vp]

        if sub.empty:
            ax.axis("off")
            continue

        # counts per (pattern, result-class)
        piv = (
            sub.groupby(["_pattern", "_plot_group3"])
            .size()
            .unstack(fill_value=0)
            .reindex(index=PATTERNS, fill_value=0)  # keep consistent pattern order
            .reindex(columns=ORDER3, fill_value=0)  # ["Match","Mismatch","Metadata Gap"]
        )

        # normalize **within each pattern** so each row sums to 1
        totals = piv.sum(axis=1).replace(0, np.nan)  # avoid div-by-zero
        piv_norm = piv.div(totals, axis=0).fillna(0.0)

        idx = np.arange(len(piv_norm.index))
        bottoms = np.zeros(len(idx))

        for col in ORDER3:  # fixed color mapping, no black border
            ax.bar(idx, piv_norm[col].values, bottom=bottoms, color=COLORS[col])
            bottoms += piv_norm[col].values

        ax.set_xticks(idx)
        ax.set_xticklabels(piv_norm.index, rotation=45, ha="right", fontsize=12)
        ax.set_ylim(0, 1.0)
        ax.set_ylabel("Proportion of Match/Mismatch/Gap", fontsize=13, weight="bold")
        ax.tick_params(axis="y", labelsize=12)

        # ↓ Title BELOW each subplot with slightly smaller gap (closer to chart)
        ax.text(
            0.5, -0.12, f"{string.ascii_lowercase[i]}) {vp}",
            transform=ax.transAxes,
            ha="center", va="top",
            fontsize=14, weight="bold"
        )

    # ---------- Legend setup ----------
    handles = [
        mpatches.Patch(color=COLORS["Match"], label="Match"),
        mpatches.Patch(color=COLORS["Mismatch"], label="Mismatch"),
        mpatches.Patch(color=COLORS["Metadata Gap"], label="Metadata Gap"),
    ]

    # If there’s an empty slot, use it for the legend
    if n_v < rows * cols:
        ax_legend = axes[n_v // cols][n_v % cols]
        ax_legend.axis("off")
        ax_legend.legend(
            handles=handles,
            loc="center",
            frameon=True,
            fancybox=True,
            fontsize=14,
            title="Categories",
            title_fontsize=15
        )

    # Turn off any other extra axes beyond the legend slot
    for j in range(n_v + 1, rows * cols):
        axes[j // cols][j % cols].axis("off")

    # ↓ Reduce padding for tighter, publication-style layout
    fig.tight_layout(pad=1.0, rect=(0, 0, 1, 0.97))
    fig.savefig(os.path.join(figs_dir, "viewpoint_by_pattern_distribution2.png"), dpi=300, bbox_inches="tight")
    plt.close(fig)

    # ---------- NEW: For each integration pattern, pie of bottlenecks (top-5 + Other) ----------
    def pie_topk_with_other(counts: pd.Series, k: int = 5) -> pd.Series:
        """Keep top-k categories; collapse the rest into 'Other'."""
        if counts.empty:
            return counts
        counts = counts.sort_values(ascending=False)
        if len(counts) <= k:
            return counts
        top = counts.iloc[:k].copy()
        other = counts.iloc[k:].sum()
        if other > 0:
            top.loc["Other"] = other
        # put "Other" at the end
        order = [c for c in top.index if c != "Other"] + (["Other"] if "Other" in top.index else [])
        return top.reindex(order)

    # Use “bottlenecks” to mean problems (Mismatch + Metadata Gap)
    n = len(PATTERNS)
    cols = 3
    rows = int(np.ceil(n / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5.4, rows * 4.6), squeeze=False)

    for i, pat in enumerate(PATTERNS):
        ax = axes[i // cols][i % cols]
        sub = df[(df["_pattern"] == pat) & (df["_is_problem"])]  # problems only
        if sub.empty:
            ax.axis("off")
            ax.set_title(f"{pat} (no bottlenecks)")
            continue

        counts = sub["bottleneck"].value_counts()
        series5 = pie_topk_with_other(counts, k=5)
        ax.pie(series5.values,
               labels=series5.index.tolist(),
               autopct=lambda p: f"{p:.1f}%")
        ax.set_title(f"{pat}")

    # turn off any extra cells
    for j in range(len(PATTERNS), rows * cols):
        axes[j // cols][j % cols].axis("off")

    fig.tight_layout()
    fig.savefig(os.path.join(figs_dir, "pie_bottleneck_distribution_by_pattern.png"), dpi=200)
    plt.close(fig)

    # ---------- NEW: Per-viewpoint pies of Match / Mismatch / Metadata Gap (percentages) ----------
    n = len(VP_ORDER)  # ["Domain","Information","Computational","Engineering","Technology"]
    cols = 3
    rows = int(np.ceil(n / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5.0, rows * 4.2), squeeze=False)

    for i, vp in enumerate(VP_ORDER):
        ax = axes[i // cols][i % cols]
        sub = df[df["_viewpoint"] == vp]
        if sub.empty:
            ax.axis("off")
            ax.set_title(f"{vp} (no rows)")
            continue

        counts = (sub["_plot_group3"]            # values are "Match", "Mismatch", "Metadata Gap"
                    .value_counts()
                    .reindex(ORDER3, fill_value=0))  # keep fixed order/colors

        total = counts.sum()
        if total == 0:
            ax.axis("off")
            ax.set_title(f"{vp} (no rows)")
            continue

        ax.pie(
            counts.values,
            labels=None,  # keep pies clean; rely on the global color guide
            autopct=lambda p: f"{p:.1f}%",
            colors=[COLORS[k] for k in ORDER3],
            textprops={"fontsize": 9}
        )
        ax.set_title(vp)

    import matplotlib.patches as mpatches
    handles = [
        mpatches.Patch(color=COLORS["Match"], label="Match"),
        mpatches.Patch(color=COLORS["Mismatch"], label="Mismatch"),
        mpatches.Patch(color=COLORS["Metadata Gap"], label="Metadata Gap"),
    ]

    # If there’s an empty slot, put the legend there
    if n < rows * cols:
        ax_legend = axes[n // cols][n % cols]
        ax_legend.axis("off")
        ax_legend.legend(handles=handles, loc="center", frameon=True, fancybox=True)

    # Turn off any remaining spare cells (after the legend one)
    for j in range(n + 1, rows * cols):
        axes[j // cols][j % cols].axis("off")

    fig.tight_layout()
    fig.savefig(os.path.join(figs_dir, "pie_match_mismatch_gap_by_viewpoint.png"), dpi=200)
    plt.close(fig)

    # ---------- 4) Field-level impact (Pareto on problems, with merged/removals) ----------
    field_counts = (
        df[df["_is_problem"]]
        .groupby("field")
        .size()
        .sort_values(ascending=False)
    )

    if not field_counts.empty:
        # Initialize new mapping container
        merged_counts = {}

        for field, count in field_counts.items():
            # 1. Merge into "Input mismatch"
            if field in {"file_formats", "(A or B).input vs AB.input", "A.input vs AB.input"}:
                merged_counts["Input"] = merged_counts.get("Input mismatch", 0) + count

            # 2. Remove communication_mechanism
            elif field == "communication_mechanism":
                continue

            # 3. Remove model_version
            elif field == "model_version":
                continue

            # 4. Remove distribution_version
            elif field == "distribution_version":
                continue

            # 5. Merge availability_of_source_code A & B
            elif field in {"availability_of_source_code (A)", "availability_of_source_code (B)"}:
                merged_counts["Availability of source code"] = merged_counts.get("Availability of source code", 0) + count

            # 6. Merge landing_page A & B
            elif field in {"landing_page (A)", "landing_page (B)"}:
                merged_counts["Landing page"] = merged_counts.get("Landing page", 0) + count

            # 7. Merge outputs into "Output"
            elif field in {"B.output vs AB.output", "(A or B).output vs AB.output"}:
                merged_counts["Output"] = merged_counts.get("Output", 0) + count

            # 8. Remove Direction (any)
            elif field == "Direction (any)":
                continue

            # Otherwise keep field as is
            else:
                merged_counts[field] = merged_counts.get(field, 0) + count

        # Convert back to Series sorted descending
        field_counts2 = pd.Series(merged_counts).sort_values(ascending=False)

        # --- Pareto chart (top-k after merge/remove) ---
        top_k = min(15, len(field_counts2))
        fc = field_counts2.iloc[:top_k]
        cum = (fc.cumsum() / fc.sum()) if fc.sum() else fc * 0

        fig = plt.figure()
        ax = fig.add_subplot(111)
        idx = np.arange(len(fc.index))
        ax.bar(idx, fc.values, color="#88AADD")
        ax.set_xticks(idx)
        ax.set_xticklabels(fc.index, rotation=90)
        ax.set_ylabel("Problem count")
        ax.set_title("Field-level impact (Pareto: top-k fields)")
        ax2 = ax.twinx()
        ax2.plot(idx, cum.values, marker="o")
        ax2.set_ylim(0, 1)
        ax2.set_ylabel("Cumulative share")
        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "field_level_pareto.png"), dpi=200)
        plt.close(fig)

        # --- Horizontal bar chart (all fields merged/remapped) ---
        fig = plt.figure(figsize=(10, max(4, 0.35 * len(field_counts2))))
        ax = fig.add_subplot(111)
        y_pos = np.arange(len(field_counts2))
        ax.barh(y_pos, field_counts2.values, color="#88AADD")
        ax.set_yticks(y_pos)
        ax.set_yticklabels(field_counts2.index)
        ax.invert_yaxis()  # largest on top
        ax.set_xlabel("Problem count")
        ax.set_ylabel("Field")
        ax.set_title("Problems by Field (merged categories)")
        fig.tight_layout()
        fig.savefig(os.path.join(figs_dir, "field_level_all_fields_horizontal.png"), dpi=200)
        plt.close(fig)

        # --- Mismatch-only (theta/pie chart) ---
        mismatch_counts = (
            df[df["_is_mismatch"]]
            .groupby("field")
            .size()
            .sort_values(ascending=False)
        )

        if not mismatch_counts.empty:
            # Apply the same remap/merge/remove rules
            mapped_mism = {}
            for k, v in mismatch_counts.items():
                newk = remap_field(k)
                if newk is None:
                    continue
                mapped_mism[newk] = mapped_mism.get(newk, 0) + v

            mismatch_counts2 = pd.Series(mapped_mism).sort_values(ascending=False)

            # --- Polar theta-style pie (mismatch only) ---

            fig = plt.figure()
            ax = fig.add_subplot(111, projection="polar")
            values = mismatch_counts2.values
            labels = mismatch_counts2.index
            total = values.sum()
            angles = np.linspace(0, 2 * np.pi, len(values) + 1)

            ax.set_theta_direction(-1)  # clockwise
            ax.set_theta_offset(np.pi / 2.0)  # start at top

            bars = ax.bar(
                angles[:-1],
                values,
                width=(2 * np.pi / len(values)),
                bottom=0,
                align="edge",
                color="#F28E8C",
                edgecolor="white"
            )

            # Annotate labels
            for angle, val, lab in zip(angles[:-1], values, labels):
                ax.text(angle + (np.pi / len(values)) / 2,
                        val + max(values) * 0.05,
                        f"{lab}\n({val})",
                        ha="center", va="center", fontsize=8)

            ax.set_title("Mismatch by Field (polar view)", va="bottom")
            ax.set_yticklabels([])  # hide radial ticks

            fig.tight_layout()
            fig.savefig(os.path.join(figs_dir, "theta_mismatch_by_field.png"), dpi=200)
            plt.close(fig)




            # --- Mismatch-only horizontal bar chart ---
            # ---------- Improved: Mismatches by Field (Horizontal Bar Chart, Final Polished) ----------
            mismatch_counts = (
                df[df["_is_mismatch"]]
                .groupby("field")
                .size()
                .sort_values(ascending=False)
            )

            if not mismatch_counts.empty:
                # Apply the same remap/merge/remove rules
                mapped_mism = {}
                for k, v in mismatch_counts.items():
                    newk = remap_field(k)
                    if newk is None:
                        continue
                    mapped_mism[newk] = mapped_mism.get(newk, 0) + v

                mismatch_counts2 = pd.Series(mapped_mism).sort_values(ascending=False)

                import seaborn as sns
                sns.set_style("whitegrid")

                fig_height = max(4, 0.45 * len(mismatch_counts2))
                fig, ax = plt.subplots(figsize=(7.5, fig_height))

                # Consistent palette
                palette = sns.color_palette("Set2", n_colors=len(mismatch_counts2))
                y_pos = np.arange(len(mismatch_counts2))

                bars = ax.barh(y_pos, mismatch_counts2.values, color=palette, edgecolor="white")

                # Add value labels
                for bar, value in zip(bars, mismatch_counts2.values):
                    ax.text(
                        value + 0.5,
                        bar.get_y() + bar.get_height() / 2,
                        f"{value}",
                        va="center",
                        ha="left",
                        fontsize=11,
                        weight="bold",
                        color="black"
                    )

                # Axis formatting
                ax.set_yticks(y_pos)
                ax.set_yticklabels(mismatch_counts2.index, fontsize=11)
                ax.invert_yaxis()
                ax.set_xlabel("Mismatch Count", fontsize=12, weight="bold")
                ax.set_ylabel("")
                ax.set_xlim(0, mismatch_counts2.max() * 1.15)
                ax.xaxis.grid(True, linestyle="--", alpha=0.6)
                sns.despine(left=True, bottom=True)

                # Title
                ax.set_title("Mismatches by Metadata Field", fontsize=13, weight="bold", pad=10)

                # Save high-quality output
                fig.tight_layout(pad=0.5)
                fig.savefig(os.path.join(figs_dir, "bar_mismatch_by_field.png"),
                            dpi=300, bbox_inches="tight", pad_inches=0.02)
                plt.close(fig)

                print(f"✅ Saved improved figure (no warnings): {os.path.join(figs_dir, 'bar_mismatch_by_field.png')}")

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np


import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np


def plot_model_metadata_results(figs_dir="figs"):
    """
    Creates a professional horizontal bar chart for
    average expert importance ratings of metadata fields,
    with a vertical gradient color bar (red→green) on the right.
    """

    os.makedirs(figs_dir, exist_ok=True)

    # --- Data ---
    data = {
        "Field": [
            "Model ID", "Input Data", "Source Code", "License",
            "Spatial Res.", "Temporal Res.", "Dimensionality", "Impl. Verification",
            "Data Sync", "Parameters", "Scope", "Exec. Instructions", "Integration Pattern",
            "Landing Page", "Assumptions", "Uncertainty Analysis", "Exec. Constraints", "Output Data",
            "Resampling Policies", "Validation", "Description",
            "Model Version", "Model Type", "Purpose & Pattern", "Software Specs",
            "Hardware Specs", "Keywords", "Error Handling", "Var. Spatial Res.",
            "Sensitivity", "Submodel ID", "Conceptual Eval.",
            "Var. Temporal Res.", "Title", "Calibration Data", "Latency",
            "Distribution Ver.", "Parallel Exec.", "Publications/Reports",
            "Acknowledgments", "Programming Lang.", "Contributor Role", "Author ID"
        ],
        "Average Rank": [
            10, 10, 10, 10, 9.75, 9.75, 9.4, 9.38, 9.25, 9.25, 9.13, 9, 9, 9,
            8.88, 8.88, 8.88, 8.858, 8.858, 8.75, 8.75, 8.63, 8.25, 8.13, 8, 8, 8,
            8, 8, 7.88, 7.75, 7.75, 7.666, 7.63, 7.5, 7.25, 7.13, 6.88, 6.88,
            6.75, 5.63, 4.63, 3.75
        ]
    }

    df = pd.DataFrame(data).sort_values("Average Rank", ascending=True)

    # --- Create color gradient (dark red → dark green) ---
    cmap = plt.colormaps["RdYlGn"]
    norm = plt.Normalize(df["Average Rank"].min(), df["Average Rank"].max())
    df["Color"] = df["Average Rank"].apply(lambda x: cmap(norm(x)))

    # --- Style setup ---
    sns.set_theme(style="white")
    plt.rcParams.update({
        "axes.titlesize": 14,
        "axes.labelsize": 13,
        "font.size": 12,
        "figure.dpi": 300,
        "savefig.dpi": 300
    })

    # --- Plot main chart ---
    fig, ax = plt.subplots(figsize=(9, 11))
    bar_height = 0.45

    bars = ax.barh(
        df["Field"],
        df["Average Rank"],
        color=df["Color"],
        edgecolor="white",
        height=bar_height
    )

    # --- Formatting ---
    ax.set_xlabel("", fontsize=14, weight="bold")
    ax.set_ylabel("")
    ax.set_xlim(3, 10.5)
    ax.tick_params(axis="y", labelsize=12)
    ax.tick_params(axis="x", labelsize=12)
    ax.set_title("", fontsize=14, weight="bold", pad=12)

    # --- Annotate bars ---
    for bar, value in zip(bars, df["Average Rank"]):
        ax.text(
            value + 0.05,
            bar.get_y() + bar.get_height() / 2,
            f"{value:.2f}",
            va="center",
            fontsize=12
        )

    # --- Add vertical color guide on right side ---
    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])

    # Align the color bar height with chart height
    cbar = fig.colorbar(sm, ax=ax, orientation="vertical", pad=0.02, fraction=0.035)
    cbar.set_label("Average Importance", fontsize=13, weight="bold")
    cbar.ax.tick_params(labelsize=11)

    # --- Clean up spines ---
    for spine in ["top", "right", "left"]:
        ax.spines[spine].set_visible(False)
    ax.spines["bottom"].set_color("gray")
    ax.spines["bottom"].set_linewidth(0.8)
    ax.grid(False)

    # --- Adjust layout for long labels ---
    fig.subplots_adjust(left=0.55, right=0.88, top=0.9, bottom=0.08)

    # --- Save figure ---
    outpath = os.path.join(figs_dir, "ModelMetadataResults.png")
    fig.savefig(outpath, bbox_inches="tight")
    plt.close(fig)
    print(f"✅ Saved figure with vertical color guide: {outpath}")



import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Patch


import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np


def plot_viewpoint_results(figs_dir="figs"):
    """
    Creates a professional, compact horizontal bar chart for
    average metadata importance by viewpoint, using a green↔red gradient.
    Bars are tightly spaced (1 bar height apart).
    """

    os.makedirs(figs_dir, exist_ok=True)

    # --- Data ---
    data = {
        "Viewpoint": ["Information", "Computational", "Technology", "Engineering", "Domain"],
        "Average Importance": [9.15, 8.50, 8.46, 7.79, 7.71]
    }

    df = pd.DataFrame(data).sort_values("Average Importance", ascending=True)

    # --- Gradient setup (red → green) ---
    cmap = plt.colormaps["RdYlGn"]
    norm = plt.Normalize(df["Average Importance"].min(), df["Average Importance"].max())
    df["Color"] = df["Average Importance"].apply(lambda x: cmap(norm(x)))

    # --- Style setup ---
    sns.set_theme(style="white")
    plt.rcParams.update({
        "axes.titlesize": 14,
        "axes.labelsize": 12,
        "font.size": 12,
        "figure.dpi": 300,
        "savefig.dpi": 300
    })

    # --- Plot ---
    fig, ax = plt.subplots(figsize=(6.5, 2.8))  # slightly smaller height
    bar_height = 0.15
    spacing = bar_height * 1.1  # minimal spacing (≈ 1 bar height apart)
    bar_y = np.arange(0, len(df) * spacing, spacing)

    bars = ax.barh(
        bar_y,
        df["Average Importance"],
        color=df["Color"],
        edgecolor="white",
        height=bar_height
    )

    # --- Formatting ---
    ax.set_yticks(bar_y)
    ax.set_yticklabels(df["Viewpoint"], fontsize=12)
    ax.set_xlim(df["Average Importance"].min() - 0.3, df["Average Importance"].max() + 0.3)
    ax.xaxis.set_visible(False)
    ax.spines["bottom"].set_visible(False)
    ax.set_ylabel("")
    ax.set_title(
        "",
        fontsize=14, weight="bold", pad=8
    )

    # --- Annotate bars ---
    for y, (bar, value) in enumerate(zip(bars, df["Average Importance"])):
        ax.text(
            value + 0.05,
            bar.get_y() + bar.get_height() / 2,
            f"{value:.2f}",
            va="center",
            fontsize=11
        )

    # --- Vertical colorbar ---
    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = fig.colorbar(sm, ax=ax, orientation="vertical", fraction=0.04, pad=0.015)
    cbar.set_label("Average Importance", fontsize=12, weight="bold")
    cbar.ax.tick_params(labelsize=10)

    # --- Clean up spines ---
    for spine in ["top", "right", "left"]:
        ax.spines[spine].set_visible(False)

    # --- Layout adjustment ---
    fig.subplots_adjust(left=0.33, right=0.88, top=0.85, bottom=0.15)

    # --- Save figure ---
    outpath = os.path.join(figs_dir, "ViewpointsResults.png")
    fig.savefig(outpath, bbox_inches="tight")
    plt.close(fig)
    print(f"✅ Saved tight-spaced gradient chart: {outpath}")





# ============================================================
# CLI main
# ============================================================

def main(argv: List[str]) -> None:
    debug = False
    args: List[str] = []
    for a in argv:
        if a == "--debug":
            debug = True
        else:
            args.append(a)

    paths: List[str] = []
    default_root = "modelsMetadataFull" if os.path.isdir("modelsMetadataFull") else "."
    scan_roots = args or [default_root]
    for a in scan_roots:
        if os.path.isdir(a):
            for root, _, files in os.walk(a):
                for fn in files:
                    if fn.lower().endswith((".yml",".yaml")):
                        paths.append(os.path.join(root, fn))
        else:
            if a.lower().endswith((".yml",".yaml")):
                paths.append(a)
        # 👇 Add this line to see how many files were added
        print(f"[DEBUG] Found {len(paths)} YAML files to process")

    if not paths:
        print("No YAML files found.")
        return

    models = load_yaml_models(paths)
    for m in models:
        try:
            extract_io(m, debug=debug)
        except Exception as e:
            print(f"Warning: failed to extract IO for {m.file}: {e}")
            print(traceback.format_exc())

    groups: Dict[str, List[ModelMeta]] = defaultdict(list)
    for m in models:
        groups[m.group].append(m)

    if debug:
        for gid, items in sorted(groups.items()):
            roles = ", ".join([f"{it.role}:{os.path.basename(it.file)}" for it in items])
            print(f"[DEBUG] group {gid}: {roles}")

    report_rows: List[Dict[str,Any]] = []
    for gid, items in sorted(groups.items()):
        A = next((x for x in items if x.role == "A"), None)
        B = next((x for x in items if x.role == "B"), None)
        AB_intended = next((x for x in items if x.role == "AB-INTENDED"), None)
        AB_integrated = next((x for x in items if x.role == "AB-INTEGRATED"), None)
        if A and B:
            try:
                # Pass AB-INTENDED
                if AB_intended:
                    rows = evaluate_group(gid, A, B, AB_intended, debug=debug)
                    for r in rows:
                        r["ab_kind"] = "INTENDED"
                    report_rows.extend(rows)

                # Pass AB-INTEGRATED
                if AB_integrated:
                    rows = evaluate_group(gid, A, B, AB_integrated, debug=debug)
                    for r in rows:
                        r["ab_kind"] = "INTEGRATED"
                    report_rows.extend(rows)
            except Exception as e:
                print(f"Warning: failed to evaluate group {gid}: {e}")
                print(traceback.format_exc())
        else:
            print(f"Warning: group {gid}: missing {'A' if not A else ''}{' and ' if (not A and not B) else ''}{'B' if not B else ''}")

    if not report_rows:
        print("No A/B pairs found to score.")
        return

    df = pd.DataFrame(report_rows)
    out_csv = "match_report.csv"
    df.to_csv(out_csv, index=False)

    # Compact console view
    preview_cols = [c for c in ["group","bottleneck","field","pattern","result"] if c in df.columns]
    print(df[preview_cols].to_string(index=False))
    print("\nSaved CSV:", out_csv)

    # Figures
    try:
        generate_figures(df)
    except Exception as e:
        print("Warning: failed to generate figures:", e)
        print(traceback.format_exc())

if __name__ == "__main__":
    main(sys.argv[1:])
    plot_model_metadata_results()
    plot_viewpoint_results()
